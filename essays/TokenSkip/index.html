<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Welcome to Shise's notebook. This site serves as a personal knowledge base for me to record my thoughts and ideas. It is also a place for me to share my knowledge and experience with the world. I hope you find something useful here. "><meta name=author content=ShiSeAB><link href=https://shiseab.github.io/notebook/essays/TokenSkip/ rel=canonical><link href=../DeepSeek-R1/ rel=prev><link href=../DEER/ rel=next><link rel=icon href=../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.12"><title>TokenSkip - ShiSe的notebook</title><link rel=stylesheet href=../../assets/stylesheets/main.2afb09e1.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"LXGW WenKai Screen GB Screen";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../css/custom.css><link rel=stylesheet href=../../css/card.css><link rel=stylesheet href=../../css/tasklist.css><link rel=stylesheet href=../../css/flink.css><link rel=stylesheet href=../../css/more_changelog.css><link rel=stylesheet href=../../css/latex.css><link rel=stylesheet href=../../css/extra.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=black data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#tokenskip class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../.. title=ShiSe的notebook class="md-header__button md-logo" aria-label=ShiSe的notebook data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> ShiSe的notebook </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> TokenSkip </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" title=分享 aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ShiSeAB/notebook.git/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> ShiSeAB/notebook </div> </a> </div> </nav> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> HOME </a> </li> <li class=md-tabs__item> <a href=../../DeepLearning/Convolution/ class=md-tabs__link> Deep Learning </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../Compiler/Lexical%20Analysis/ class=md-tabs__link> CS课程 </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=ShiSe的notebook class="md-nav__button md-logo" aria-label=ShiSe的notebook data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> ShiSe的notebook </label> <div class=md-nav__source> <a href=https://github.com/ShiSeAB/notebook.git/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> ShiSeAB/notebook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../.. class="md-nav__link "> <span class=md-ellipsis> HOME </span> </a> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> HOME </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Deep Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Deep Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../DeepLearning/Convolution/ class=md-nav__link> <span class=md-ellipsis> 卷积神经网络 </span> </a> </li> <li class=md-nav__item> <a href=../../DeepLearning/Modern%20CNN/ class=md-nav__link> <span class=md-ellipsis> 现代卷积神经网络架构 </span> </a> </li> <li class=md-nav__item> <a href=../../DeepLearning/Recurrent%20neural%20network/ class=md-nav__link> <span class=md-ellipsis> 循环神经网络 </span> </a> </li> <li class=md-nav__item> <a href=../../DeepLearning/Modern%20RNN/ class=md-nav__link> <span class=md-ellipsis> 现代循环神经网络 </span> </a> </li> <li class=md-nav__item> <a href="../../DeepLearning/Attention Mechanisms" class=md-nav__link> <span class=md-ellipsis> 注意力机制 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> CS课程 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> CS课程 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex> <span class=md-ellipsis> 编译原理 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> 编译原理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Compiler/Lexical%20Analysis/ class=md-nav__link> <span class=md-ellipsis> 词法分析 </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1_2> <label class=md-nav__link for=__nav_3_1_2 id=__nav_3_1_2_label tabindex=0> <span class=md-ellipsis> 语法分析 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1_2> <span class="md-nav__icon md-icon"></span> 语法分析 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Compiler/Parsing/ class=md-nav__link> <span class=md-ellipsis> Top-Down </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/Parsing%20-%202/ class=md-nav__link> <span class=md-ellipsis> Bottom-Up </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href="../../Commpiler/Abstract Syntax.md" class=md-nav__link> <span class=md-ellipsis> 抽象语法 </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/Semantic%20Analysis/ class=md-nav__link> <span class=md-ellipsis> 语义分析 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex> <span class=md-ellipsis> 自然语言处理导论 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 自然语言处理导论 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../nlp/Deep%20Learning%20Basic/ class=md-nav__link> <span class=md-ellipsis> 深度学习基础 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3 checked> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex> <span class=md-ellipsis> 论文阅读 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> 论文阅读 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../DeepSeek-R1/ class=md-nav__link> <span class=md-ellipsis> DeepSeek-R1 </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> TokenSkip </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> TokenSkip </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-preliminaries class=md-nav__link> <span class=md-ellipsis> 1. Preliminaries </span> </a> <nav class=md-nav aria-label="1. Preliminaries"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-token-importance class=md-nav__link> <span class=md-ellipsis> 1. token Importance </span> </a> </li> <li class=md-nav__item> <a href=#2-cot-recovery class=md-nav__link> <span class=md-ellipsis> 2. CoT recovery </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#2-tokenskip class=md-nav__link> <span class=md-ellipsis> 2. TokenSkip </span> </a> <nav class=md-nav aria-label="2. TokenSkip"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-token-pruning class=md-nav__link> <span class=md-ellipsis> 1. Token Pruning </span> </a> </li> <li class=md-nav__item> <a href=#2-training class=md-nav__link> <span class=md-ellipsis> 2. Training </span> </a> </li> <li class=md-nav__item> <a href=#3-inference class=md-nav__link> <span class=md-ellipsis> 3. Inference </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-experiment class=md-nav__link> <span class=md-ellipsis> 3. Experiment </span> </a> <nav class=md-nav aria-label="3. Experiment"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#实验细节 class=md-nav__link> <span class=md-ellipsis> 实验细节 </span> </a> </li> <li class=md-nav__item> <a href=#baseline class=md-nav__link> <span class=md-ellipsis> Baseline </span> </a> </li> <li class=md-nav__item> <a href=#实验结果 class=md-nav__link> <span class=md-ellipsis> 实验结果 </span> </a> </li> <li class=md-nav__item> <a href=#分析 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> <nav class=md-nav aria-label=分析> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-compression-ratio class=md-nav__link> <span class=md-ellipsis> 1. Compression Ratio </span> </a> </li> <li class=md-nav__item> <a href=#2-importance-metric class=md-nav__link> <span class=md-ellipsis> 2. Importance Metric </span> </a> </li> <li class=md-nav__item> <a href=#3-length-budget class=md-nav__link> <span class=md-ellipsis> 3. length Budget </span> </a> </li> <li class=md-nav__item> <a href=#4-case class=md-nav__link> <span class=md-ellipsis> 4. case </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../DEER/ class=md-nav__link> <span class=md-ellipsis> DEER </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-preliminaries class=md-nav__link> <span class=md-ellipsis> 1. Preliminaries </span> </a> <nav class=md-nav aria-label="1. Preliminaries"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-token-importance class=md-nav__link> <span class=md-ellipsis> 1. token Importance </span> </a> </li> <li class=md-nav__item> <a href=#2-cot-recovery class=md-nav__link> <span class=md-ellipsis> 2. CoT recovery </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#2-tokenskip class=md-nav__link> <span class=md-ellipsis> 2. TokenSkip </span> </a> <nav class=md-nav aria-label="2. TokenSkip"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-token-pruning class=md-nav__link> <span class=md-ellipsis> 1. Token Pruning </span> </a> </li> <li class=md-nav__item> <a href=#2-training class=md-nav__link> <span class=md-ellipsis> 2. Training </span> </a> </li> <li class=md-nav__item> <a href=#3-inference class=md-nav__link> <span class=md-ellipsis> 3. Inference </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-experiment class=md-nav__link> <span class=md-ellipsis> 3. Experiment </span> </a> <nav class=md-nav aria-label="3. Experiment"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#实验细节 class=md-nav__link> <span class=md-ellipsis> 实验细节 </span> </a> </li> <li class=md-nav__item> <a href=#baseline class=md-nav__link> <span class=md-ellipsis> Baseline </span> </a> </li> <li class=md-nav__item> <a href=#实验结果 class=md-nav__link> <span class=md-ellipsis> 实验结果 </span> </a> </li> <li class=md-nav__item> <a href=#分析 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> <nav class=md-nav aria-label=分析> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-compression-ratio class=md-nav__link> <span class=md-ellipsis> 1. Compression Ratio </span> </a> </li> <li class=md-nav__item> <a href=#2-importance-metric class=md-nav__link> <span class=md-ellipsis> 2. Importance Metric </span> </a> </li> <li class=md-nav__item> <a href=#3-length-budget class=md-nav__link> <span class=md-ellipsis> 3. length Budget </span> </a> </li> <li class=md-nav__item> <a href=#4-case class=md-nav__link> <span class=md-ellipsis> 4. case </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=tokenskip>TokenSkip<a class=headerlink href=#tokenskip title="Permanent link">&para;</a></h1> <p><strong>研究原因</strong>：due to the autoregressive nature of LLM decoding, longer CoT outputs lead to a linear increase in inference latency, adversely affecting user experience, particularly when the CoT exceeds 10,000 tokens</p> <p><strong>idea</strong>： TokenSkip enables LLMs to skip tokens with less semantic importance (e.g., ) and learn shortcuts between critical reasoning tokens, facilitating controllable CoT compression</p> <p><img alt=image-20250423202909100 src=../TokenSkip.assets/image-20250423202909100.png></p> <h2 id=1-preliminaries>1. Preliminaries<a class=headerlink href=#1-preliminaries title="Permanent link">&para;</a></h2> <h3 id=1-token-importance>1. token Importance<a class=headerlink href=#1-token-importance title="Permanent link">&para;</a></h3> <p>启发问题：Does every token in the CoT output contribute equally to deriving the answer?” </p> <p>回答：no</p> <p><strong>Selective Context</strong> （measure the importance of tokens in a piece of text based on the semantic confidence of LLMs）方法：</p> <p><img alt=image-20250423204205290 src=../TokenSkip.assets/image-20250423204205290.png></p> <p>但是 Selective Context 方法存在局限性：</p> <ul> <li>大语言模型困惑度的固有特性导致句子末尾的标记重要性度量值较低（即置信度较高）。Such position dependency impacts the factual importance measurement of each token</li> <li>因果大语言模型中的 unidirectional attention mechanism 可能无法捕捉文本中 token 重要性所需的所有关键信息。</li> </ul> <p><strong>LMLingua-2</strong> 引入了利用类似 BERT 的 bidirectional LM 来测量 token重要性：利用GPT-4 to label each token as “important” or not and trains the bidirectional LM with a token classification objective</p> <p><img alt=image-20250423205210022 src=../TokenSkip.assets/image-20250423205210022.png></p> <p>得到下图的可视化（上为 Selective Context，下为 LLMLingua-2）：</p> <p><img alt=image-20250423203008566 src=../TokenSkip.assets/image-20250423203008566.png></p> <h3 id=2-cot-recovery>2. CoT recovery<a class=headerlink href=#2-cot-recovery title="Permanent link">&para;</a></h3> <p>问题：Are LLMs capable of restoring the CoT process from compressed outputs?</p> <p>答案是肯定的，如下图：</p> <p><img alt=image-20250423222734625 src=../TokenSkip.assets/image-20250423222734625.png></p> <p>这种能力确保了压缩思维链的可解释性得以维持。</p> <p>综上所述，上述实证分析强调了修剪冗余标记以提高思维链（CoT）效率的潜力，以及大语言模型（LLMs）从压缩输出中恢复思维链的能力。</p> <h2 id=2-tokenskip>2. TokenSkip<a class=headerlink href=#2-tokenskip title="Permanent link">&para;</a></h2> <p><img alt=image-20250423223358137 src=../TokenSkip.assets/image-20250423223358137.png></p> <h3 id=1-token-pruning>1. Token Pruning<a class=headerlink href=#1-token-pruning title="Permanent link">&para;</a></h3> <p>从大语言模型（LLM）的思维链输出中修剪掉冗余 token，并利用这些经过修剪的思维链轨迹对大语言模型进行微调。The token pruning process is guided by the concept of token importance.</p> <p>过程：根据LLMLingua-2计算每个思维链token的语义重要性 <span class=arithmatex>\(I(c)\)</span>，据此排序，给定期望压缩率 <span class=arithmatex>\(\gamma\)</span> ，代表修剪阈值（比如γ=0.6，保留60%的token）</p> <h3 id=2-training>2. Training<a class=headerlink href=#2-training title="Permanent link">&para;</a></h3> <p>数据准备：</p> <p>首先用包含 N 个样本的训练集 D 输入模型 M 得到 N 条思维链（过滤错误答案的trajectories），然后对其进行 pruning，得到三元组：⟨question, compressed CoT, answer⟩，最终输入格式为：</p> <p><img alt=image-20250423233849289 src=../TokenSkip.assets/image-20250423233849289.png></p> <p>即[问题、分隔符、压缩比率、分隔符、压缩后的思维链、答案]，EOS为序列结束符，<span class=arithmatex>\(\gamma\)</span> 以数值形式嵌入[问题] [EOS] '压缩比例0.6' [EOS]. output sequence <strong><span class=arithmatex>\(y\)</span></strong> 是压缩后的思维链和答案的拼接，损失函数如下：</p> <p><img alt=image-20250424114325901 src=../TokenSkip.assets/image-20250424114325901.png></p> <p>为了保留大语言模型的推理能力，还在训练数据中纳入了一部分原始思维链轨迹，将其压缩率*γ*设为 1。</p> <p>将上述 Input 作为训练数据用来训练模型（loRA微调），使其学会跳过不重要的标记。</p> <h3 id=3-inference>3. Inference<a class=headerlink href=#3-inference title="Permanent link">&para;</a></h3> <p>推理时，prompt格式如下：</p> <p>[question x, [EOS], <span class=arithmatex>\(\gamma\)</span> ,[EOS]]</p> <p>输出序列包含压缩后的思维链和答案。</p> <h2 id=3-experiment>3. Experiment<a class=headerlink href=#3-experiment title="Permanent link">&para;</a></h2> <p>实验数据集： GSM8K &amp; MATH-500；实验模型： LLaMA-3.1-8B-Instruct &amp; Qwen2.5-Instruct series</p> <p>评估指标：accuracy, the number of CoT tokens, and inference latency per sample，用来自DeepSeek-Math的脚本来评估模型性能。此外，CoT 的实际压缩率也会用于与指导压缩率比较。</p> <h4 id=实验细节>实验细节<a class=headerlink href=#实验细节 title="Permanent link">&para;</a></h4> <p>LLMLingua2压缩 CoT，压缩率 <span class=arithmatex>\(\gamma\)</span> 从 {0.5, 0.6, 0.7, 0.8, 0.9, 1.0} 中随机选择，采用LoRA 微调（秩 r 设置为 8，缩放参数 α 设置为 16，仅调整0.2%的模型参数）</p> <p>训练成本低，在 3090 GPU 上训练 70 亿参数模型大约需要 2 小时，训练 140 亿参数模型大约需要 2.5 小时。在推理时，对于 GSM8K 数据集，最大标记数 max_len 设置为 512；对于 MATH-500，则为1024. （<span class=arithmatex>\(max\_len \times \gamma\)</span>）</p> <p>Pytorch 2.1.0 on 2×NVIDIA GeForce RTX 3090 GPU (24GB) with CUDA 12.1, and an Intel(R) Xeon(R) Platinum 8370C CPU with 32 cores. </p> <h4 id=baseline>Baseline<a class=headerlink href=#baseline title="Permanent link">&para;</a></h4> <ol> <li>Prompt-based Reduction：通过prompt 指示大模型在CoT过程中减少固定比例的输出token</li> <li>Truncation: 强制截断，即限制输出标记的最大数量，将思维链的输出压缩到一个固定的长度。</li> </ol> <h4 id=实验结果>实验结果<a class=headerlink href=#实验结果 title="Permanent link">&para;</a></h4> <p>TokenSkip 在 GSM8K 数据集上使用 Qwen2.5-Instruct 系列模型的性能表现：可以发现，模型规模越大，压缩率对性能影响更小（Qwen2.5-14B-Instruct 在修剪掉 40% 的标记时，几乎没有性能下降（下降幅度小于 0.4%）。即使在压缩率为 0.5 的情况下，该模型仍保持着较强的推理能力，性能仅下降 2%）</p> <p><img src=./TokenSkip.assets/image-20250424121103426.png alt=image-20250424121103426 style=zoom:50%;></p> <p>与baseline对比：</p> <p><img alt=image-20250424150928839 src=../TokenSkip.assets/image-20250424150928839.png></p> <p>prompt-based reduction 方法中，实际压缩率与目标压缩率不符。在 Truncation 方法中，虽然实际与目标压缩率相符，但是性能显著下降（GSM8K 数据集上的准确率下降了 79%，在 MATH-500 数据集上下降了 21%）。而TokenSkip 法不仅实现压缩率相符、性能也没有出现显著变化，响应时间变快。</p> <h4 id=分析>分析<a class=headerlink href=#分析 title="Permanent link">&para;</a></h4> <h5 id=1-compression-ratio>1. Compression Ratio<a class=headerlink href=#1-compression-ratio title="Permanent link">&para;</a></h5> <p>为了探究在 Compression Ratio 较低（压缩较多）情况下 TokenSkip 的性能表现，训练变体模型 'More Ratio'，用于测当 <span class=arithmatex>\(\gamma = 0.3 ~and~ 0.4\)</span> 的情况，发现符合程度大幅降低，且在整体上符合程度不如 TokenSkip：</p> <p><img src=./TokenSkip.assets/image-20250424152439233.png alt=image-20250424152439233 style=zoom:50%;></p> <p>假设将其归因于对 reasoning tokens 的过度修剪，使得补全内容时关键内容丢失，阻碍模型有效训练。</p> <h5 id=2-importance-metric>2. Importance Metric<a class=headerlink href=#2-importance-metric title="Permanent link">&para;</a></h5> <p>不同模型给 token 重要性打分，其中，让GPT-4o 给出思维链轨迹的最佳压缩格式建议，这一情况被称为 GPT-4o-Optimal 。将所有由 GPT-4o 生成的训练数据用于训练 TokenSkip 变体，用 [optimal] token 来提示模型，得到 GPT-4o-Optimal 结果。</p> <p><img src=./TokenSkip.assets/image-20250424153300243.png alt=image-20250424153300243 style=zoom:50%;></p> <h5 id=3-length-budget>3. length Budget<a class=headerlink href=#3-length-budget title="Permanent link">&para;</a></h5> <p><img src=./TokenSkip.assets/image-20250424161734492.png alt=image-20250424161734492 style=zoom:50%;></p> <h5 id=4-case>4. case<a class=headerlink href=#4-case title="Permanent link">&para;</a></h5> <p>这些示例清晰地表明，TokenSkip 使得大语言模型能够学习关键推理标记之间的捷径，而不是从头生成更短的思维链（CoT）.</p> <ul> <li>数值和数学方程式会被优先保留</li> <li>okenSkip 并没有减少推理步骤的数量，而是修剪了这些步骤中多余的标记</li> </ul> <p><img alt=image-20250424162932254 src=../TokenSkip.assets/image-20250424162932254.png></p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=页脚> <a href=../DeepSeek-R1/ class="md-footer__link md-footer__link--prev" aria-label="上一页: DeepSeek-R1"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> 上一页 </span> <div class=md-ellipsis> DeepSeek-R1 </div> </div> </a> <a href=../DEER/ class="md-footer__link md-footer__link--next" aria-label="下一页: DEER"> <div class=md-footer__title> <span class=md-footer__direction> 下一页 </span> <div class=md-ellipsis> DEER </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2023 ~ now | 🚀 Chen Wu (ShiSe) </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script> <script src=../../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../../js/baidu-tongji.js></script> <script src=../../js/katex.js></script> <script src=../../js/mathjax.js></script> <script src=https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script> </body> </html>