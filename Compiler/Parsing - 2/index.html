<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Welcome to Shise's notebook. This site serves as a personal knowledge base for me to record my thoughts and ideas. It is also a place for me to share my knowledge and experience with the world. I hope you find something useful here. "><meta name=author content=ShiSeAB><link href=https://shiseab.github.io/notebook/Compiler/Parsing%20-%202/ rel=canonical><link href=../Parsing/ rel=prev><link href=../../nlp/Deep%20Learning%20Basic/ rel=next><link rel=icon href=../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.9"><title>Bottom-Up - ShiSe的notebook</title><link rel=stylesheet href=../../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"LXGW WenKai Screen GB Screen";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../css/custom.css><link rel=stylesheet href=../../css/card.css><link rel=stylesheet href=../../css/tasklist.css><link rel=stylesheet href=../../css/flink.css><link rel=stylesheet href=../../css/more_changelog.css><link rel=stylesheet href=../../css/latex.css><link rel=stylesheet href=../../css/extra.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=black data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#buttom-up-parsing class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../.. title=ShiSe的notebook class="md-header__button md-logo" aria-label=ShiSe的notebook data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> ShiSe的notebook </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Bottom-Up </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" title=分享 aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ShiSeAB/notebook.git/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> ShiSeAB/notebook </div> </a> </div> </nav> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> HOME </a> </li> <li class=md-tabs__item> <a href=../../DeepLearning/Convolution/ class=md-tabs__link> Deep Learning </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../Lexical%20Analysis/ class=md-tabs__link> CS课程 </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=ShiSe的notebook class="md-nav__button md-logo" aria-label=ShiSe的notebook data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> ShiSe的notebook </label> <div class=md-nav__source> <a href=https://github.com/ShiSeAB/notebook.git/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> ShiSeAB/notebook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../.. class="md-nav__link "> <span class=md-ellipsis> HOME </span> </a> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> HOME </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Deep Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Deep Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../DeepLearning/Convolution/ class=md-nav__link> <span class=md-ellipsis> 卷积神经网络 </span> </a> </li> <li class=md-nav__item> <a href=../../DeepLearning/Modern%20CNN/ class=md-nav__link> <span class=md-ellipsis> 现代卷积神经网络架构 </span> </a> </li> <li class=md-nav__item> <a href=../../DeepLearning/Recurrent%20neural%20network/ class=md-nav__link> <span class=md-ellipsis> 循环神经网络 </span> </a> </li> <li class=md-nav__item> <a href=../../DeepLearning/Modern%20RNN/ class=md-nav__link> <span class=md-ellipsis> 现代循环神经网络 </span> </a> </li> <li class=md-nav__item> <a href="../../DeepLearning/Attention Mechanisms" class=md-nav__link> <span class=md-ellipsis> 注意力机制 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> CS课程 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> CS课程 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1 checked> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex> <span class=md-ellipsis> 编译原理 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=true> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> 编译原理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Lexical%20Analysis/ class=md-nav__link> <span class=md-ellipsis> 词法分析 </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1_2 checked> <label class=md-nav__link for=__nav_3_1_2 id=__nav_3_1_2_label tabindex=0> <span class=md-ellipsis> 语法分析 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_1_2_label aria-expanded=true> <label class=md-nav__title for=__nav_3_1_2> <span class="md-nav__icon md-icon"></span> 语法分析 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Parsing/ class=md-nav__link> <span class=md-ellipsis> Top-Down </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Bottom-Up </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Bottom-Up </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-shift-reduce class=md-nav__link> <span class=md-ellipsis> 1. Shift-Reduce </span> </a> </li> <li class=md-nav__item> <a href=#2-lr0分析 class=md-nav__link> <span class=md-ellipsis> 2. LR(0)分析 </span> </a> <nav class=md-nav aria-label="2. LR(0)分析"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-lr0-parsing-nfa class=md-nav__link> <span class=md-ellipsis> 2.1 LR(0) Parsing NFA </span> </a> </li> <li class=md-nav__item> <a href=#22-lr0-parsing-dfa class=md-nav__link> <span class=md-ellipsis> 2.2 LR(0) Parsing DFA </span> </a> <nav class=md-nav aria-label="2.2 LR(0) Parsing DFA"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#221-nfa---dfa class=md-nav__link> <span class=md-ellipsis> 2.2.1 NFA -&gt;&gt; DFA </span> </a> </li> <li class=md-nav__item> <a href=#222-直接构造 class=md-nav__link> <span class=md-ellipsis> 2.2.2 直接构造 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#23-lr0-parsing-分析表 class=md-nav__link> <span class=md-ellipsis> 2.3 LR(0) Parsing 分析表 </span> </a> </li> <li class=md-nav__item> <a href=#24-lr0-parsing-过程 class=md-nav__link> <span class=md-ellipsis> 2.4 LR(0) Parsing 过程 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-slr分析 class=md-nav__link> <span class=md-ellipsis> 3. SLR分析 </span> </a> <nav class=md-nav aria-label="3. SLR分析"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-slr1-parsing思路 class=md-nav__link> <span class=md-ellipsis> 3.1 SLR(1) Parsing思路 </span> </a> </li> <li class=md-nav__item> <a href=#32-问题与局限 class=md-nav__link> <span class=md-ellipsis> 3.2 问题与局限 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-lr1-分析 class=md-nav__link> <span class=md-ellipsis> 4. LR(1) 分析 </span> </a> </li> <li class=md-nav__item> <a href=#5-lalr1 class=md-nav__link> <span class=md-ellipsis> 5. LALR(1) </span> </a> <nav class=md-nav aria-label="5. LALR(1)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#parsing-generator class=md-nav__link> <span class=md-ellipsis> Parsing Generator </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-小结 class=md-nav__link> <span class=md-ellipsis> 6. 小结 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex> <span class=md-ellipsis> 自然语言处理导论 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 自然语言处理导论 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../nlp/Deep%20Learning%20Basic/ class=md-nav__link> <span class=md-ellipsis> 深度学习基础 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-shift-reduce class=md-nav__link> <span class=md-ellipsis> 1. Shift-Reduce </span> </a> </li> <li class=md-nav__item> <a href=#2-lr0分析 class=md-nav__link> <span class=md-ellipsis> 2. LR(0)分析 </span> </a> <nav class=md-nav aria-label="2. LR(0)分析"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-lr0-parsing-nfa class=md-nav__link> <span class=md-ellipsis> 2.1 LR(0) Parsing NFA </span> </a> </li> <li class=md-nav__item> <a href=#22-lr0-parsing-dfa class=md-nav__link> <span class=md-ellipsis> 2.2 LR(0) Parsing DFA </span> </a> <nav class=md-nav aria-label="2.2 LR(0) Parsing DFA"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#221-nfa---dfa class=md-nav__link> <span class=md-ellipsis> 2.2.1 NFA -&gt;&gt; DFA </span> </a> </li> <li class=md-nav__item> <a href=#222-直接构造 class=md-nav__link> <span class=md-ellipsis> 2.2.2 直接构造 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#23-lr0-parsing-分析表 class=md-nav__link> <span class=md-ellipsis> 2.3 LR(0) Parsing 分析表 </span> </a> </li> <li class=md-nav__item> <a href=#24-lr0-parsing-过程 class=md-nav__link> <span class=md-ellipsis> 2.4 LR(0) Parsing 过程 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-slr分析 class=md-nav__link> <span class=md-ellipsis> 3. SLR分析 </span> </a> <nav class=md-nav aria-label="3. SLR分析"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-slr1-parsing思路 class=md-nav__link> <span class=md-ellipsis> 3.1 SLR(1) Parsing思路 </span> </a> </li> <li class=md-nav__item> <a href=#32-问题与局限 class=md-nav__link> <span class=md-ellipsis> 3.2 问题与局限 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-lr1-分析 class=md-nav__link> <span class=md-ellipsis> 4. LR(1) 分析 </span> </a> </li> <li class=md-nav__item> <a href=#5-lalr1 class=md-nav__link> <span class=md-ellipsis> 5. LALR(1) </span> </a> <nav class=md-nav aria-label="5. LALR(1)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#parsing-generator class=md-nav__link> <span class=md-ellipsis> Parsing Generator </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-小结 class=md-nav__link> <span class=md-ellipsis> 6. 小结 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=buttom-up-parsing>Buttom-Up Parsing<a class=headerlink href=#buttom-up-parsing title="Permanent link">&para;</a></h1> <p>该部分主要介绍Bottom-Up方法：</p> <p><img alt=image-20250317135852620 src=../Parsing%20-%202.assets/image-20250317135852620.png></p> <p>文法：<span class=arithmatex>\(LR(0),SLR(1),LR(1),LALR(1)\)</span></p> <p>表达力排序：</p> <p><img alt=image-20250317141921774 src=../Parsing%20-%202.assets/image-20250317141921774.png></p> <h2 id=1-shift-reduce>1. Shift-Reduce<a class=headerlink href=#1-shift-reduce title="Permanent link">&para;</a></h2> <p>Bottom-Up Parsing: 从串w规约为文法开始符号S</p> <ul> <li>规约: 与某产生式**右部**相匹配的特定子串, 被替换为该产生式**头部**的非终结符</li> <li>但问题是：什么时候规约（读入多少token后规约）？规约到哪个非终结符？</li> </ul> <p>LR 分析的一般模式：shift-reduce</p> <p>例：我们发现光标移动Shift过程中什么时候规约Reduce是很重要的（做更重要的决策），且树是从下面往上建的</p> <p><img alt=image-20250306151428433 src=../Parsing%20-%202.assets/image-20250306151428433.png></p> <p>构建这棵树的过程是最右推导的逆过程(Rightmost derivation in reverse)，<strong>最右推导</strong> 过程为：</p> <p><span class=arithmatex>\(E \Rightarrow E+(E) \Rightarrow E+(int) \Rightarrow E+(E)+(int) \Rightarrow E+(int)+(int) \Rightarrow int+(int)+(int)\)</span></p> <p>Shift-Reduce是基于栈的：</p> <p><img alt=image-20250313134035295 src=../Parsing%20-%202.assets/image-20250313134035295.png></p> <ul> <li>Symbol Stack：存 left-substring <span class=arithmatex>\(\alpha\)</span> (terminal or nonterminal)</li> <li>Input Stream：存剩余输入 <span class=arithmatex>\(\beta\)</span></li> <li><strong>Shift</strong> 意为 push next input(terminal) on to top of stack</li> <li><strong>Reduce</strong> 规则如下：</li> <li>栈顶应match RHS of rule (<span class=arithmatex>\(X -&gt; AB\)</span>，栈顶字符应match AB)</li> <li>将栈顶match的RHS pop出来(<span class=arithmatex>\(pop~BA\)</span>)</li> <li>接着push the LHS onto the Stack(<span class=arithmatex>\(push~X\)</span>)</li> </ul> <h2 id=2-lr0分析>2. LR(0)分析<a class=headerlink href=#2-lr0分析 title="Permanent link">&para;</a></h2> <p>假设下次用到的 rule 为 <span class=arithmatex>\(X\rightarrow \alpha \beta\)</span>，使用它进行规约前，栈顶可能什么都没有，也可能只有一个 <span class=arithmatex>\(\alpha\)</span>，又可能match了RHS，这是不确定的，对应操作也应不同。</p> <p>所以维护一个状态，用于记录当前识别的进度，以便知道栈顶内容是否可以进行规约了。</p> <p><strong>项</strong> 类似于Automata中的状态：</p> <p><img alt=image-20250313135552543 src=../Parsing%20-%202.assets/image-20250313135552543.png></p> <p><img alt=image-20250313135908199 src=../Parsing%20-%202.assets/image-20250313135908199.png></p> <p>状态跳转：</p> <p><img alt=image-20250313135719256 src=../Parsing%20-%202.assets/image-20250313135719256.png></p> <p>状态+跳转 -&gt; 自动机，这种相应的有穷自动机就是LR(0)自动机：</p> <ul> <li>文法产生式是有限的</li> <li>每个产生式右部的长度也是有限的</li> <li>故称为有穷</li> </ul> <h3 id=21-lr0-parsing-nfa>2.1 LR(0) Parsing NFA<a class=headerlink href=#21-lr0-parsing-nfa title="Permanent link">&para;</a></h3> <p>​ 该NFA不是指直接用来识别LR(0)语言的自动机（NFA只能识别正则语言，然而LR(0)是上下文无关语言）。该NFA是用来“记录当前识别进度”的（帮助判断栈顶内容是否可归约了）。</p> <p><strong>起始&amp;终结状态</strong></p> <p>增加新开始符号 <span class=arithmatex>\(S'\)</span> 并加入产生式 <span class=arithmatex>\(S'\rightarrow S\$\)</span> </p> <p><img alt=image-20250317144135653 src=../Parsing%20-%202.assets/image-20250317144135653.png></p> <p><strong>状态迁移关系</strong></p> <p><img alt=image-20250317144245797 src=../Parsing%20-%202.assets/image-20250317144245797.png></p> <p><img alt=image-20250317144300750 src=../Parsing%20-%202.assets/image-20250317144300750.png></p> <p><strong>例</strong></p> <p><img alt=image-20250317144616309 src=../Parsing%20-%202.assets/image-20250317144616309.png></p> <h3 id=22-lr0-parsing-dfa>2.2 LR(0) Parsing DFA<a class=headerlink href=#22-lr0-parsing-dfa title="Permanent link">&para;</a></h3> <h4 id=221-nfa---dfa>2.2.1 NFA -&gt;&gt; DFA<a class=headerlink href=#221-nfa---dfa title="Permanent link">&para;</a></h4> <p>利用子集构造法：</p> <p><img alt=image-20250317144955067 src=../Parsing%20-%202.assets/image-20250317144955067.png></p> <h4 id=222-直接构造>2.2.2 直接构造<a class=headerlink href=#222-直接构造 title="Permanent link">&para;</a></h4> <p>首先是项集构造，DFA起始状态为 <span class=arithmatex>\(S'\rightarrow ·S\$\)</span>，根据下述算法扩充项集，即将以S为LHS的项加进去：</p> <p><img alt=image-20250317145543090 src=../Parsing%20-%202.assets/image-20250317145543090.png></p> <p>接着用GOTO算法进行状态转移，其中 <span class=arithmatex>\(Goto(I,X)\)</span> 定义为 <span class=arithmatex>\(I\)</span> 中所有形如 <span class=arithmatex>\(A \rightarrow \alpha·X\beta\)</span> 的项所对应的项 <span class=arithmatex>\(A\rightarrow \alpha X·\beta\)</span> 的集合的闭包，<span class=arithmatex>\(X\)</span> 为input：</p> <p><img alt=image-20250317154519081 src=../Parsing%20-%202.assets/image-20250317154519081.png></p> <p>用Closure补全项集：</p> <p><img alt=image-20250317161903463 src=../Parsing%20-%202.assets/image-20250317161903463.png></p> <p>收敛条件：</p> <p><img alt=image-20250317161929831 src=../Parsing%20-%202.assets/image-20250317161929831.png></p> <p>不过考试一般不考LR(0)，因为比较简单。</p> <h3 id=23-lr0-parsing-分析表>2.3 LR(0) Parsing 分析表<a class=headerlink href=#23-lr0-parsing-分析表 title="Permanent link">&para;</a></h3> <p>从LR(0) Parsing DFA到语法分析表：</p> <p><img alt=image-20250317234129112 src=../Parsing%20-%202.assets/image-20250317234129112.png></p> <ul> <li><span class=arithmatex>\(s2\)</span> 代表 <strong>shift</strong> 并go to state 2，<span class=arithmatex>\(T[1,x] = s2\)</span> 代表在状态1读入x，就shift并跳转到状态2，此时一般dot不在end.</li> <li>dot at the end时，就要 <strong>reduce</strong> 了，例如 <span class=arithmatex>\(T[3,x] = r2\)</span> ，代表用生成式2 <span class=arithmatex>\(S\rightarrow y\)</span> 进行规约。</li> <li><strong>accept</strong> 说明接受输入串，一般是在final state。</li> <li>在 <strong>Goto</strong> 表中，输入是 non-terminal，<span class=arithmatex>\(T[1,S]=g4\)</span> 代表输入S，goto 状态4，而在Action表中输入是terminal</li> </ul> <h3 id=24-lr0-parsing-过程>2.4 LR(0) Parsing 过程<a class=headerlink href=#24-lr0-parsing-过程 title="Permanent link">&para;</a></h3> <p><img alt=image-20250318110818445 src=../Parsing%20-%202.assets/image-20250318110818445.png></p> <p><img alt=image-20250318110829054 src=../Parsing%20-%202.assets/image-20250318110829054.png></p> <p>算法：</p> <p><img alt=image-20250318111227476 src=../Parsing%20-%202.assets/image-20250318111227476.png></p> <p>例：</p> <p>起始在状态1；输入x后到状态2；再输入x还是状态2；接着输入y跳转到状态3；由于下一个输入就是 $ ，所以reduce，|y|=1，pop状态3，将Goto[2,S]=5入栈；在状态5下reduce，|xS| = 2, pop状态5、2，将Goto[2,S] = 5入栈；</p> <p><img alt=image-20250318111453893 src=../Parsing%20-%202.assets/image-20250318111453893.png></p> <p>考点：Grammar的DFA长什么样、预测表长什么样，给一个input string，状态栈的变化。</p> <p>由于LR(0)分析器不会查看下一个输入符号，所以没有足够的上下文来做出更正确(或者说更”聪明”)的决定。</p> <h2 id=3-slr分析>3. SLR分析<a class=headerlink href=#3-slr分析 title="Permanent link">&para;</a></h2> <p>SLR(1) 中的 S 表示 Simple。SLR(1) Parsing 在 LR(0) 的基础上通过简单的判断尝试解决冲突。</p> <h3 id=31-slr1-parsing思路>3.1 SLR(1) Parsing思路<a class=headerlink href=#31-slr1-parsing思路 title="Permanent link">&para;</a></h3> <p>SLR(1) 在生成 LR(0) DFA 后，计算每一个 non-terminal 的 Follow Set，并根据这两者创建 SLR(1) 分析表。</p> <ul> <li>每步规约都应满足 <span class=arithmatex>\(t\in Follow(E)\)</span>，只有当下一个输入 token <span class=arithmatex>\(t\in Follow(E) = {\)</span>}$ ，才能进行规约。</li> </ul> <p><img alt=image-20250318220819475 src=../Parsing%20-%202.assets/image-20250318220819475.png></p> <p>例：</p> <p><img alt=image-20250318220842750 src=../Parsing%20-%202.assets/image-20250318220842750.png></p> <p>只有当输入为 $ 时，状态3才能进行规约；同理状态6. 状态5输入可以是{+，$}.</p> <p>如果这样构造出的 SLR(1) Parsing Table 没有含冲突的表项，那么称这个文法为 SLR(1) Grammar，否则不是。</p> <h3 id=32-问题与局限>3.2 问题与局限<a class=headerlink href=#32-问题与局限 title="Permanent link">&para;</a></h3> <p>SLR(1) 解决了LR(0) 的shift or reduce 和用哪个production 规约的问题。但Follow集仍是 “合理但可能不够精确的近似”。</p> <p><img alt=image-20250318222513256 src=../Parsing%20-%202.assets/image-20250318222513256.png></p> <h2 id=4-lr1-分析>4. LR(1) 分析<a class=headerlink href=#4-lr1-分析 title="Permanent link">&para;</a></h2> <p>包含更多信息，精确指明何时应该规约。</p> <p>LR(1)项的形式： <span class=arithmatex>\(A\rightarrow \alpha ·\beta,a\)</span></p> <ul> <li><span class=arithmatex>\(a\)</span> 称为向前看符号(lookahead symbol)，可以是terminal或$</li> </ul> <p>闭包计算：</p> <p><img alt=image-20250319101629437 src=../Parsing%20-%202.assets/image-20250319101629437.png></p> <p><img alt=image-20250319102237226 src=../Parsing%20-%202.assets/image-20250319102237226.png></p> <ul> <li><span class=arithmatex>\(w\)</span> 是terminal</li> </ul> <p>例-计算该Grammar的DFA状态1：</p> <p><img alt=image-20250319102520857 src=../Parsing%20-%202.assets/image-20250319102520857.png></p> <p><img alt=image-20250319102533040 src=../Parsing%20-%202.assets/image-20250319102533040.png></p> <p><img alt=image-20250319102544649 src=../Parsing%20-%202.assets/image-20250319102544649.png></p> <p><img alt=image-20250319102639185 src=../Parsing%20-%202.assets/image-20250319102639185.png></p> <p><img alt=image-20250319102707310 src=../Parsing%20-%202.assets/image-20250319102707310.png></p> <p>Goto计算：比较简单</p> <p><img alt=image-20250319102737070 src=../Parsing%20-%202.assets/image-20250319102737070.png></p> <p>Reduce Action：</p> <p><img alt=image-20250319102822080 src=../Parsing%20-%202.assets/image-20250319102822080.png></p> <p>局限: LR(1) 的parsing table 会非常大,状态很多.</p> <h2 id=5-lalr1>5. LALR(1)<a class=headerlink href=#5-lalr1 title="Permanent link">&para;</a></h2> <p>在LR(1) 中,有的状态只有 look ahead symbol不同,由此可以考虑合并,从而减少状态数:</p> <p><img alt=image-20250320134453773 src=../Parsing%20-%202.assets/image-20250320134453773.png></p> <ul> <li> <p>定义 <strong>core</strong> : core of a set of LR items is the set of first components(不带look ahead symbol)</p> </li> <li> <p>core 相同的状态可以合并. 合并后的状态称为LALR(1) states</p> </li> <li> <p>LALR(1) Parsing DFA 就是由LR(1) DFA合并直到所有states的core都不同</p> </li> <li> <p>合并过程中,边也要相应改变</p> </li> </ul> <p><img alt=image-20250320135229104 src=../Parsing%20-%202.assets/image-20250320135229104.png></p> <p>例:</p> <p><img alt=image-20250320134923816 src=../Parsing%20-%202.assets/image-20250320134923816.png></p> <h3 id=parsing-generator>Parsing Generator<a class=headerlink href=#parsing-generator title="Permanent link">&para;</a></h3> <p>Yacc 是基于 LALR(1), 用BNF形式书写的语法分析器的生成器, 与Lex的联系为:</p> <p><img alt=image-20250320135900682 src=../Parsing%20-%202.assets/image-20250320135900682.png></p> <ul> <li>消除二义性</li> <li>冲突解决</li> </ul> <h2 id=6-小结>6. 小结<a class=headerlink href=#6-小结 title="Permanent link">&para;</a></h2> <p><img alt=image-20250320135959261 src=../Parsing%20-%202.assets/image-20250320135959261.png></p> <p><img alt=image-20250320140236432 src=../Parsing%20-%202.assets/image-20250320140236432.png></p> <ul> <li>LR(0) SLR 都不会显式地考虑look ahead symbol,项集比较简单</li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=页脚> <a href=../Parsing/ class="md-footer__link md-footer__link--prev" aria-label="上一页: Top-Down"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> 上一页 </span> <div class=md-ellipsis> Top-Down </div> </div> </a> <a href=../../nlp/Deep%20Learning%20Basic/ class="md-footer__link md-footer__link--next" aria-label="下一页: 深度学习基础"> <div class=md-footer__title> <span class=md-footer__direction> 下一页 </span> <div class=md-ellipsis> 深度学习基础 </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2023 ~ now | 🚀 Chen Wu (ShiSe) </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../../js/baidu-tongji.js></script> <script src=../../js/katex.js></script> <script src=../../js/mathjax.js></script> <script src=https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script> </body> </html>