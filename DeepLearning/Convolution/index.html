<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Welcome to Shise's notebook. This site serves as a personal knowledge base for me to record my thoughts and ideas. It is also a place for me to share my knowledge and experience with the world. I hope you find something useful here. "><meta name=author content=ShiSeAB><link href=https://shiseab.github.io/notebook/DeepLearning/Convolution/ rel=canonical><link rel=prev href=../..><link href=../Modern%20CNN/ rel=next><link rel=icon href=../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.12"><title>卷积神经网络 - ShiSe的notebook</title><link rel=stylesheet href=../../assets/stylesheets/main.2afb09e1.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"LXGW WenKai Screen GB Screen";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../css/custom.css><link rel=stylesheet href=../../css/card.css><link rel=stylesheet href=../../css/tasklist.css><link rel=stylesheet href=../../css/flink.css><link rel=stylesheet href=../../css/more_changelog.css><link rel=stylesheet href=../../css/latex.css><link rel=stylesheet href=../../css/extra.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=black data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#卷积神经网络 class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../.. title=ShiSe的notebook class="md-header__button md-logo" aria-label=ShiSe的notebook data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> ShiSe的notebook </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 卷积神经网络 </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" title=分享 aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ShiSeAB/notebook.git/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> ShiSeAB/notebook </div> </a> </div> </nav> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> HOME </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> Deep Learning </a> </li> <li class=md-tabs__item> <a href=../../Compiler/Lexical%20Analysis/ class=md-tabs__link> CS课程 </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=ShiSe的notebook class="md-nav__button md-logo" aria-label=ShiSe的notebook data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> ShiSe的notebook </label> <div class=md-nav__source> <a href=https://github.com/ShiSeAB/notebook.git/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> ShiSeAB/notebook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../.. class="md-nav__link "> <span class=md-ellipsis> HOME </span> </a> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> HOME </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Deep Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Deep Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 卷积神经网络 </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 卷积神经网络 </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-多层感知机的限制 class=md-nav__link> <span class=md-ellipsis> 1. 多层感知机的限制 </span> </a> <nav class=md-nav aria-label="1. 多层感知机的限制"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#11-平移不变性-translation-invariance class=md-nav__link> <span class=md-ellipsis> 1.1 平移不变性 Translation Invariance </span> </a> </li> <li class=md-nav__item> <a href=#12-局部性 class=md-nav__link> <span class=md-ellipsis> 1.2 局部性 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#2-卷积层 class=md-nav__link> <span class=md-ellipsis> 2 卷积层 </span> </a> <nav class=md-nav aria-label="2 卷积层"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-二维交叉相关 class=md-nav__link> <span class=md-ellipsis> 2.1 二维交叉相关 </span> </a> </li> <li class=md-nav__item> <a href=#22-一维和三维交叉相关 class=md-nav__link> <span class=md-ellipsis> 2.2 一维和三维交叉相关 </span> </a> </li> <li class=md-nav__item> <a href=#23-代码实现 class=md-nav__link> <span class=md-ellipsis> 2.3 代码实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-填充padding与步幅stride class=md-nav__link> <span class=md-ellipsis> 3. 填充(Padding)与步幅(Stride) </span> </a> <nav class=md-nav aria-label="3. 填充(Padding)与步幅(Stride)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-padding class=md-nav__link> <span class=md-ellipsis> 3.1 Padding </span> </a> </li> <li class=md-nav__item> <a href=#32-stride class=md-nav__link> <span class=md-ellipsis> 3.2 Stride </span> </a> </li> <li class=md-nav__item> <a href=#33-代码实现 class=md-nav__link> <span class=md-ellipsis> 3.3 代码实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-多输入多输出通道 class=md-nav__link> <span class=md-ellipsis> 4. 多输入多输出通道 </span> </a> <nav class=md-nav aria-label="4. 多输入多输出通道"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-多输入通道 class=md-nav__link> <span class=md-ellipsis> 4.1 多输入通道 </span> </a> </li> <li class=md-nav__item> <a href=#42-多输出通道 class=md-nav__link> <span class=md-ellipsis> 4.2 多输出通道 </span> </a> </li> <li class=md-nav__item> <a href=#43-1-times-1卷积层 class=md-nav__link> <span class=md-ellipsis> 4.3 1 \(\times\) 1卷积层 </span> </a> </li> <li class=md-nav__item> <a href=#44-代码实现 class=md-nav__link> <span class=md-ellipsis> 4.4 代码实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5-池化层 class=md-nav__link> <span class=md-ellipsis> 5. 池化层 </span> </a> <nav class=md-nav aria-label="5. 池化层"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51-最大汇聚层和平均汇聚层 class=md-nav__link> <span class=md-ellipsis> 5.1 最大汇聚层和平均汇聚层 </span> </a> </li> <li class=md-nav__item> <a href=#52-填充与步幅 class=md-nav__link> <span class=md-ellipsis> 5.2 填充与步幅 </span> </a> </li> <li class=md-nav__item> <a href=#53-代码实现 class=md-nav__link> <span class=md-ellipsis> 5.3 代码实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-lenet class=md-nav__link> <span class=md-ellipsis> 6. LeNet </span> </a> <nav class=md-nav aria-label="6. LeNet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#61-介绍 class=md-nav__link> <span class=md-ellipsis> 6.1 介绍 </span> </a> </li> <li class=md-nav__item> <a href=#62-代码实现 class=md-nav__link> <span class=md-ellipsis> 6.2 代码实现 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Modern%20CNN/ class=md-nav__link> <span class=md-ellipsis> 现代卷积神经网络架构 </span> </a> </li> <li class=md-nav__item> <a href=../Recurrent%20neural%20network/ class=md-nav__link> <span class=md-ellipsis> 循环神经网络 </span> </a> </li> <li class=md-nav__item> <a href=../Modern%20RNN/ class=md-nav__link> <span class=md-ellipsis> 现代循环神经网络 </span> </a> </li> <li class=md-nav__item> <a href="../Attention Mechanisms" class=md-nav__link> <span class=md-ellipsis> 注意力机制 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> CS课程 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> CS课程 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> 编译原理 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> 编译原理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Compiler/Lexical%20Analysis/ class=md-nav__link> <span class=md-ellipsis> 词法分析 </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1_2> <label class=md-nav__link for=__nav_3_1_2 id=__nav_3_1_2_label tabindex=0> <span class=md-ellipsis> 语法分析 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1_2> <span class="md-nav__icon md-icon"></span> 语法分析 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Compiler/Parsing/ class=md-nav__link> <span class=md-ellipsis> Top-Down </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/Parsing%20-%202/ class=md-nav__link> <span class=md-ellipsis> Bottom-Up </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href="../../Commpiler/Abstract Syntax.md" class=md-nav__link> <span class=md-ellipsis> 抽象语法 </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/Semantic%20Analysis/ class=md-nav__link> <span class=md-ellipsis> 语义分析 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> 自然语言处理导论 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 自然语言处理导论 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../nlp/Deep%20Learning%20Basic/ class=md-nav__link> <span class=md-ellipsis> 深度学习基础 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> 论文阅读 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> 论文阅读 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../essays/DeepSeek-R1/ class=md-nav__link> <span class=md-ellipsis> DeepSeek-R1 </span> </a> </li> <li class=md-nav__item> <a href=../../essays/TokenSkip/ class=md-nav__link> <span class=md-ellipsis> TokenSkip </span> </a> </li> <li class=md-nav__item> <a href=../../essays/DEER/ class=md-nav__link> <span class=md-ellipsis> DEER </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-多层感知机的限制 class=md-nav__link> <span class=md-ellipsis> 1. 多层感知机的限制 </span> </a> <nav class=md-nav aria-label="1. 多层感知机的限制"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#11-平移不变性-translation-invariance class=md-nav__link> <span class=md-ellipsis> 1.1 平移不变性 Translation Invariance </span> </a> </li> <li class=md-nav__item> <a href=#12-局部性 class=md-nav__link> <span class=md-ellipsis> 1.2 局部性 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#2-卷积层 class=md-nav__link> <span class=md-ellipsis> 2 卷积层 </span> </a> <nav class=md-nav aria-label="2 卷积层"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-二维交叉相关 class=md-nav__link> <span class=md-ellipsis> 2.1 二维交叉相关 </span> </a> </li> <li class=md-nav__item> <a href=#22-一维和三维交叉相关 class=md-nav__link> <span class=md-ellipsis> 2.2 一维和三维交叉相关 </span> </a> </li> <li class=md-nav__item> <a href=#23-代码实现 class=md-nav__link> <span class=md-ellipsis> 2.3 代码实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-填充padding与步幅stride class=md-nav__link> <span class=md-ellipsis> 3. 填充(Padding)与步幅(Stride) </span> </a> <nav class=md-nav aria-label="3. 填充(Padding)与步幅(Stride)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-padding class=md-nav__link> <span class=md-ellipsis> 3.1 Padding </span> </a> </li> <li class=md-nav__item> <a href=#32-stride class=md-nav__link> <span class=md-ellipsis> 3.2 Stride </span> </a> </li> <li class=md-nav__item> <a href=#33-代码实现 class=md-nav__link> <span class=md-ellipsis> 3.3 代码实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-多输入多输出通道 class=md-nav__link> <span class=md-ellipsis> 4. 多输入多输出通道 </span> </a> <nav class=md-nav aria-label="4. 多输入多输出通道"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-多输入通道 class=md-nav__link> <span class=md-ellipsis> 4.1 多输入通道 </span> </a> </li> <li class=md-nav__item> <a href=#42-多输出通道 class=md-nav__link> <span class=md-ellipsis> 4.2 多输出通道 </span> </a> </li> <li class=md-nav__item> <a href=#43-1-times-1卷积层 class=md-nav__link> <span class=md-ellipsis> 4.3 1 \(\times\) 1卷积层 </span> </a> </li> <li class=md-nav__item> <a href=#44-代码实现 class=md-nav__link> <span class=md-ellipsis> 4.4 代码实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5-池化层 class=md-nav__link> <span class=md-ellipsis> 5. 池化层 </span> </a> <nav class=md-nav aria-label="5. 池化层"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51-最大汇聚层和平均汇聚层 class=md-nav__link> <span class=md-ellipsis> 5.1 最大汇聚层和平均汇聚层 </span> </a> </li> <li class=md-nav__item> <a href=#52-填充与步幅 class=md-nav__link> <span class=md-ellipsis> 5.2 填充与步幅 </span> </a> </li> <li class=md-nav__item> <a href=#53-代码实现 class=md-nav__link> <span class=md-ellipsis> 5.3 代码实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-lenet class=md-nav__link> <span class=md-ellipsis> 6. LeNet </span> </a> <nav class=md-nav aria-label="6. LeNet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#61-介绍 class=md-nav__link> <span class=md-ellipsis> 6.1 介绍 </span> </a> </li> <li class=md-nav__item> <a href=#62-代码实现 class=md-nav__link> <span class=md-ellipsis> 6.2 代码实现 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=卷积神经网络>卷积神经网络<a class=headerlink href=#卷积神经网络 title="Permanent link">&para;</a></h1> <h2 id=1-多层感知机的限制>1. 多层感知机的限制<a class=headerlink href=#1-多层感知机的限制 title="Permanent link">&para;</a></h2> <ul> <li>输入是一维向量 <span class=arithmatex>\(x \in \mathbb{R}^{1*d}\)</span>的情况下，权重 <span class=arithmatex>\(W\in \mathbb{R}^{h*d}\)</span> (h为向量 <span class=arithmatex>\(h\)</span> 的大小)只需要为二维张量:</li> </ul> <p><img alt=image-20250301145818180 src=../Convolution.assets/image-20250301145818180.png></p> <blockquote> <p>​ <span class=arithmatex>\(h_j = \sum_{j}{W_{i,j}{x_j}} + b_j\)</span></p> </blockquote> <ul> <li>在输入是二维图像 <span class=arithmatex>\(X\)</span> 的情况下，隐藏层表示 <span class=arithmatex>\(H\)</span> 在数学上是一个矩阵，在代码中表示为二维张量。使用 <span class=arithmatex>\([X]_{i,j}\)</span> 和 <span class=arithmatex>\([H]_{i,j}\)</span> 分别表示输入图像和隐藏表示中位置 <span class=arithmatex>\((i,j)\)</span> 处的像素。此时要求权重 <span class=arithmatex>\(W\)</span> 为一个四维张量：</li> </ul> <p><img alt=image-20250301150053475 src=../Convolution.assets/image-20250301150053475.png></p> <p>为了节省参数（避免参数随着输入变大而变得无限多），我们假设有一个”检测器“扫描图像，将图像分割成多个区域(blocks)，并为每个区域包含目标的可能性打分。而索引a和b通过在正偏移和负偏移之间移动覆盖了整个图像，对于隐藏表示中任意给定位置 <span class=arithmatex>\(( i , j )\)</span> 处的像素值 <span class=arithmatex>\([H]_{i,j}\)</span> , 通过对 <span class=arithmatex>\(X\)</span> 中以 <span class=arithmatex>\((i,j)\)</span> 为中心的像素进行加权求和得到，权重为 <span class=arithmatex>\(v_{i,j,a,b}\)</span> , 实现了 ”检测器“ 功能。</p> <p>其中，从 <span class=arithmatex>\(W\)</span> 到 <span class=arithmatex>\(V\)</span> 的转化至少形式上的转化，这两个四阶张量的元素之间存在一一对应的关系：</p> <p>$$ [V]<em i_j_i_a_j_b=i,j,i+a,j+b>{i,j,a,b} = [W]</em> $$</p> <h3 id=11-平移不变性-translation-invariance>1.1 平移不变性 Translation Invariance<a class=headerlink href=#11-平移不变性-translation-invariance title="Permanent link">&para;</a></h3> <p>​ 检测对象在输入 <span class=arithmatex>\(X\)</span> 中的平移，应该仅导致隐藏表示 <span class=arithmatex>\(H\)</span> 中的平移。也就是说不管出现在图像中的哪个位置，神经网络的底层应该对相同的图像区域做出类似的响应。</p> <p>​ 但如公式 <span class=arithmatex>\(h_{i,j} = \sum_{a,b}{v_{i,j,a,b}{x_{i+a,j+b}}}\)</span> 所示，<span class=arithmatex>\(i，j\)</span>的变化会导致 权重 <span class=arithmatex>\(v\)</span> 发生变化，使得到的 <span class=arithmatex>\(h\)</span> 也发生变化，违反了平移不变性。</p> <p>​ 所以，<span class=arithmatex>\(v\)</span> 不应该依赖于 <span class=arithmatex>\((i,j)\)</span>，定义：<span class=arithmatex>\(v_{i,j,a,b} = v_{a,b}\)</span>，得到：</p> <p>$$ h_{i,j} = \sum_{a,b}{v_{a,b}}{x_{i+a,j+b}} $$ ​ </p> <p>这就是2维交叉相关，增加了重复性，减少参数数量，降低了模型复杂度</p> <h3 id=12-局部性>1.2 局部性<a class=headerlink href=#12-局部性 title="Permanent link">&para;</a></h3> <p>​ 神经网络的底层应该只探索输入图像中的局部区域，而不考虑图像远处区域的内容。为了收集用来训练参数 <span class=arithmatex>\([H]_{i,j}\)</span> 的相关信息，</p> <p>在 <span class=arithmatex>\(|a|&gt; \Delta\)</span> 和 <span class=arithmatex>\(|b| &gt; \Delta\)</span> 的范围之外，我们可以设置 <span class=arithmatex>\([V]_{a,b} = 0\)</span>，故将公式重写为：</p> <p>$$ [H]<em a=a>{a,j} = u + \sum</em>[V]}^{\Delta}\sum_{b = -\Delta}^{\Delta<em i_a_j_b=i+a,j+b>{a,b}[X]</em> $$ ​ </p> <p>​ <span class=arithmatex>\(V\)</span> 被称为**卷积核**（convolution kernel）或者**滤波器**（filter），亦或简单地称之为该卷积层的**权重**.</p> <h2 id=2-卷积层>2 卷积层<a class=headerlink href=#2-卷积层 title="Permanent link">&para;</a></h2> <p>核矩阵和偏移是可学习的参数，核矩阵的大小是**超参数**</p> <h3 id=21-二维交叉相关>2.1 二维交叉相关<a class=headerlink href=#21-二维交叉相关 title="Permanent link">&para;</a></h3> <p><img alt=image-20250301162234639 src=../Convolution.assets/image-20250301162234639.png></p> <h3 id=22-一维和三维交叉相关>2.2 一维和三维交叉相关<a class=headerlink href=#22-一维和三维交叉相关 title="Permanent link">&para;</a></h3> <p><img alt=image-20250301162419126 src=../Convolution.assets/image-20250301162419126.png></p> <ul> <li>一维可以做文本、语言和时序序列</li> <li>三维可以做视频、医学图像和气象地图</li> </ul> <h3 id=23-代码实现>2.3 代码实现<a class=headerlink href=#23-代码实现 title="Permanent link">&para;</a></h3> <p>见 <a href="[6.2. 图像卷积 — 动手学深度学习 2.0.0 documentation](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/conv-layer.html#id4)">李沐学ai对应章节</a></p> <h2 id=3-填充padding与步幅stride>3. 填充(Padding)与步幅(Stride)<a class=headerlink href=#3-填充padding与步幅stride title="Permanent link">&para;</a></h2> <h3 id=31-padding>3.1 Padding<a class=headerlink href=#31-padding title="Permanent link">&para;</a></h3> <p>​ 在应用多层卷积时，我们常常丢失边缘像素。 由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。 但随着我们应用许多连续卷积层，累积丢失的像素数就多了。 解决这个问题的简单方法即为填充（padding）：在输入图像的边界填充元素（通常填充元素是0）。</p> <p><img alt=image-20250303180154181 src=../Convolution.assets/image-20250303180154181.png></p> <p>如果添加 <span class=arithmatex>\(P_h\)</span> 行填充（一半顶部一半底部），<span class=arithmatex>\(P_w\)</span>列填充（一半左侧一半右侧），那么输出大小为：</p> <div class=arithmatex>\[ (n_h - k_h+p_h+1)\times(n_w-k_w+p_w+1) \]</div> <p>所以，为了使得输出不丢失边缘像素，我们设置 <span class=arithmatex>\(p_h = k_h-1\)</span> 和 <span class=arithmatex>\(p_w = k_w-1\)</span>，使输入和输出具有相同的高度和宽度。</p> <ul> <li>假设 <span class=arithmatex>\(k_h\)</span>是奇数，我们将在高度的两侧填充 <span class=arithmatex>\(p_h/2\)</span> 行</li> <li>如果 <span class=arithmatex>\(k_h\)</span> 是偶数，则一种可能性是在输入顶部填充 <span class=arithmatex>\(⌈p_h/2⌉\)</span> 行，在底部填充 <span class=arithmatex>\(⌊p_h/2⌋\)</span> 行。同理，我们填充宽度的两侧。</li> </ul> <h3 id=32-stride>3.2 Stride<a class=headerlink href=#32-stride title="Permanent link">&para;</a></h3> <p>步幅用于减少输出大小。</p> <p><img src=./Convolution.assets/image-20250303181237780.png alt=image-20250303181237780 style=zoom:50%;></p> <p><img src=./Convolution.assets/image-20250303181405145.png alt=image-20250303181405145 style=zoom:50%;></p> <p>​ 上面两种情况是为了向上取整。</p> <h3 id=33-代码实现>3.3 代码实现<a class=headerlink href=#33-代码实现 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>from</span><span class=w> </span><span class=nn>torch</span><span class=w> </span><span class=kn>import</span> <span class=n>nn</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=c1># 为了方便起见，我们定义了一个计算卷积层的函数。</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=c1># 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=k>def</span><span class=w> </span><span class=nf>comp_conv2d</span><span class=p>(</span><span class=n>conv2d</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>    <span class=c1># 这里的（1，1）表示批量大小和通道数都是1</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>    <span class=n>X</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>    <span class=n>Y</span> <span class=o>=</span> <span class=n>conv2d</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>    <span class=c1># 省略前两个维度：批量大小和通道</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>    <span class=k>return</span> <span class=n>Y</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>Y</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>:])</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=c1># 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=n>conv2d</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=n>comp_conv2d</span><span class=p>(</span><span class=n>conv2d</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span><span class=o>.</span><span class=n>shape</span>
</span></code></pre></div> <p>结果为：<code>torch.Size([8, 8])</code>，因为8-3+1+2 = 8</p> <p>当卷积核的高度和宽度不同时，我们可以填充不同的高度和宽度，使输出和输入具有相同的高度和宽度：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=n>conv2d</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span> <span class=n>padding</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>comp_conv2d</span><span class=p>(</span><span class=n>conv2d</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span><span class=o>.</span><span class=n>shape</span>
</span></code></pre></div> <p>结果同上，因为8-5+1+2x2 = 8，8-3+1+1x2 = 8.</p> <p>我们将高度和宽度的步幅设置为2，从而将输入的高度和宽度减半：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=n>conv2d</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>comp_conv2d</span><span class=p>(</span><span class=n>conv2d</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span><span class=o>.</span><span class=n>shape</span>
</span></code></pre></div> <p>结果为 <code>torch.Size([4, 4])</code>，(8-3+1+1*2)/2 = 4.</p> <p>接下来是一个稍微复杂的例子：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=n>conv2d</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>),</span> <span class=n>padding</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>stride</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=n>comp_conv2d</span><span class=p>(</span><span class=n>conv2d</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span><span class=o>.</span><span class=n>shape</span>
</span></code></pre></div> <p>答案为 <code>torch.Size([2, 2])</code>，(8-3+1+0*2)/3 = 2, (8-5+1+1x2)/4 = 2（向上取整）</p> <h2 id=4-多输入多输出通道>4. 多输入多输出通道<a class=headerlink href=#4-多输入多输出通道 title="Permanent link">&para;</a></h2> <h3 id=41-多输入通道>4.1 多输入通道<a class=headerlink href=#41-多输入通道 title="Permanent link">&para;</a></h3> <p>​ 当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。</p> <p>​ 假设通道数为 <span class=arithmatex>\(c_i\)</span>，那么卷积核的大小为 <span class=arithmatex>\(c_i \times k_h\times k_w\)</span></p> <p><img alt=image-20250303205857595 src=../Convolution.assets/image-20250303205857595.png></p> <h3 id=42-多输出通道>4.2 多输出通道<a class=headerlink href=#42-多输出通道 title="Permanent link">&para;</a></h3> <p>​ 到目前为止，不论有多少输入通道，我们还只有一个输出通道。在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。直观地说，我们可以将每个通道看作对不同特征的响应。</p> <p>​ 用 <span class=arithmatex>\(c_i\)</span> 和 <span class=arithmatex>\(c_o\)</span> 分别表示输入和输出通道的数目，为了获得多个通道的输出，我们可以为每个输出通道创建一个形状为 <span class=arithmatex>\(c_i \times k_h\times k_w\)</span> 的卷积核张量，最终：</p> <p><img alt=image-20250303210636107 src=../Convolution.assets/image-20250303210636107.png></p> <h3 id=43-1-times-1卷积层>4.3 1 <span class=arithmatex>\(\times\)</span> 1卷积层<a class=headerlink href=#43-1-times-1卷积层 title="Permanent link">&para;</a></h3> <p>​ 不识别空间模式，只是融合通道：</p> <p><img alt=image-20250303211255720 src=../Convolution.assets/image-20250303211255720.png></p> <h3 id=44-代码实现>4.4 代码实现<a class=headerlink href=#44-代码实现 title="Permanent link">&para;</a></h3> <p>实现多输入通道互相关运算，即对每个通道执行互相关操作，然后将结果相加。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=kn>from</span><span class=w> </span><span class=nn>d2l</span><span class=w> </span><span class=kn>import</span> <span class=n>torch</span> <span class=k>as</span> <span class=n>d2l</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=k>def</span><span class=w> </span><span class=nf>corr2d_multi_in</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>K</span><span class=p>):</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>    <span class=c1># 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=k>return</span> <span class=nb>sum</span><span class=p>(</span><span class=n>d2l</span><span class=o>.</span><span class=n>corr2d</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span><span class=p>,</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>K</span><span class=p>))</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a><span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>],</span> <span class=p>[</span><span class=mf>3.0</span><span class=p>,</span> <span class=mf>4.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>],</span> <span class=p>[</span><span class=mf>6.0</span><span class=p>,</span> <span class=mf>7.0</span><span class=p>,</span> <span class=mf>8.0</span><span class=p>]],</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>               <span class=p>[[</span><span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>],</span> <span class=p>[</span><span class=mf>4.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>6.0</span><span class=p>],</span> <span class=p>[</span><span class=mf>7.0</span><span class=p>,</span> <span class=mf>8.0</span><span class=p>,</span> <span class=mf>9.0</span><span class=p>]]])</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=n>K</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>],</span> <span class=p>[</span><span class=mf>2.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>]],</span> <span class=p>[[</span><span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>],</span> <span class=p>[</span><span class=mf>3.0</span><span class=p>,</span> <span class=mf>4.0</span><span class=p>]]])</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=n>corr2d_multi_in</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>K</span><span class=p>)</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=c1>#output：</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=c1>#tensor([[ 56.,  72.],</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a><span class=c1>#        [104., 120.]])</span>
</span></code></pre></div> <p>实现计算多个通道的输出的互相关函数：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=k>def</span><span class=w> </span><span class=nf>corr2d_multi_in_out</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>K</span><span class=p>):</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>    <span class=c1># 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>    <span class=c1># 最后将所有结果都叠加在一起</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>corr2d_multi_in</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span> <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>K</span><span class=p>],</span> <span class=mi>0</span><span class=p>)</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=n>K</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>K</span><span class=p>,</span> <span class=n>K</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>K</span> <span class=o>+</span> <span class=mi>2</span><span class=p>),</span> <span class=mi>0</span><span class=p>)</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=n>K</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=c1>#K从3个维度变成4个维度：输出是3，输入是2，宽高为2*2</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=c1>#torch.Size([3, 2, 2, 2])</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=n>corr2d_multi_in_out</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>K</span><span class=p>)</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a><span class=c1>#tensor([[[ 56.,  72.],</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a><span class=c1>#         [104., 120.]],</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a><span class=c1>#        [[ 76., 100.],</span>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a><span class=c1>#         [148., 172.]],</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a><span class=c1>#        [[ 96., 128.],</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a><span class=c1>#         [192., 224.]]])</span>
</span></code></pre></div> <p>使用全连接层实现<span class=arithmatex>\(1\times1\)</span>卷积:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=k>def</span><span class=w> </span><span class=nf>corr2d_multi_in_out_1x1</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>K</span><span class=p>):</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>    <span class=n>c_i</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>    <span class=n>c_o</span> <span class=o>=</span> <span class=n>K</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>    <span class=c1>#变成c_i个大小为h*w的向量</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=n>X</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=n>c_i</span><span class=p>,</span> <span class=n>h</span> <span class=o>*</span> <span class=n>w</span><span class=p>))</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>    <span class=n>K</span> <span class=o>=</span> <span class=n>K</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=n>c_o</span><span class=p>,</span> <span class=n>c_i</span><span class=p>))</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>    <span class=c1># 全连接层中的矩阵乘法</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>    <span class=n>Y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>K</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>    <span class=k>return</span> <span class=n>Y</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=n>c_o</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>))</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a><span class=c1>#验证</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a><span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a><span class=n>K</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a><span class=n>Y1</span> <span class=o>=</span> <span class=n>corr2d_multi_in_out_1x1</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>K</span><span class=p>)</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a><span class=n>Y2</span> <span class=o>=</span> <span class=n>corr2d_multi_in_out</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>K</span><span class=p>)</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a><span class=k>assert</span> <span class=nb>float</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>Y1</span> <span class=o>-</span> <span class=n>Y2</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>())</span> <span class=o>&lt;</span> <span class=mf>1e-6</span>
</span></code></pre></div> <h2 id=5-池化层>5. 池化层<a class=headerlink href=#5-池化层 title="Permanent link">&para;</a></h2> <p>pooling具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性</p> <h3 id=51-最大汇聚层和平均汇聚层>5.1 最大汇聚层和平均汇聚层<a class=headerlink href=#51-最大汇聚层和平均汇聚层 title="Permanent link">&para;</a></h3> <p>池运算是确定性的，我们通常计算汇聚窗口中所有元素的最大值或平均值.</p> <ul> <li>maximum pooling：获取每个窗口中最强模式信号</li> </ul> <p><img alt=image-20250303220005022 src=../Convolution.assets/image-20250303220005022.png></p> <ul> <li>average pooling：获取每个窗口中平均模式信号</li> </ul> <h3 id=52-填充与步幅>5.2 填充与步幅<a class=headerlink href=#52-填充与步幅 title="Permanent link">&para;</a></h3> <p>与卷积层一样，汇聚层也可以改变输出形状。和以前一样，我们可以通过填充和步幅以获得所需的输出形状。</p> <p>但是池化层没有可学习的参数，kernel是固定的；且不可融合通道，输入通道数 = 输出通道数</p> <h3 id=53-代码实现>5.3 代码实现<a class=headerlink href=#53-代码实现 title="Permanent link">&para;</a></h3> <p>略</p> <h2 id=6-lenet>6. LeNet<a class=headerlink href=#6-lenet title="Permanent link">&para;</a></h2> <h3 id=61-介绍>6.1 介绍<a class=headerlink href=#61-介绍 title="Permanent link">&para;</a></h3> <p>总体由两个部分组成：</p> <ul> <li>卷积编码器：由两个卷积层组成，学习图片空间信息</li> <li>全连接层密集块：由三个全连接层组成，转化到类别空间</li> </ul> <p><img alt=image-20250304112130582 src=../Convolution.assets/image-20250304112130582.png></p> <ul> <li> <p>第一个卷积层 5*5，输出通道为6(矩阵大小不变)；</p> </li> <li> <p>接着第一个池化层2*2，输出通道为6</p> </li> <li> <p>第二个卷积层5*5，输出通道16(矩阵大小变化)</p> </li> <li> <p>第二个池化层2*2，输出通道16</p> </li> <li> <p>接着接两个全连接层</p> </li> <li>最后输出层(也可视作全连接层)</li> </ul> <p><img alt=image-20250304200418339 src=../Convolution.assets/image-20250304200418339.png></p> <h3 id=62-代码实现>6.2 代码实现<a class=headerlink href=#62-代码实现 title="Permanent link">&para;</a></h3> <p>只需要实例化一个<code>Sequential</code>块并将需要的层连接在一起：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=kn>from</span><span class=w> </span><span class=nn>torch</span><span class=w> </span><span class=kn>import</span> <span class=n>nn</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=kn>from</span><span class=w> </span><span class=nn>d2l</span><span class=w> </span><span class=kn>import</span> <span class=n>torch</span> <span class=k>as</span> <span class=n>d2l</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>    <span class=c1>#设置padding使得输入输出矩阵大小一致</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>(),</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=n>nn</span><span class=o>.</span><span class=n>AvgPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>(),</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a>    <span class=n>nn</span><span class=o>.</span><span class=n>AvgPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>16</span> <span class=o>*</span> <span class=mi>5</span> <span class=o>*</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>120</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>(),</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>120</span><span class=p>,</span> <span class=mi>84</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>(),</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>84</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span></code></pre></div> <p>模型训练，修改代码，使其能在GPU上计算：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=k>def</span><span class=w> </span><span class=nf>evaluate_accuracy_gpu</span><span class=p>(</span><span class=n>net</span><span class=p>,</span> <span class=n>data_iter</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span> <span class=c1>#@save</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;使用GPU计算模型在数据集上的精度&quot;&quot;&quot;</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>net</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>        <span class=n>net</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>  <span class=c1># 设置为评估模式</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>        <span class=k>if</span> <span class=ow>not</span> <span class=n>device</span><span class=p>:</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>            <span class=n>device</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=nb>iter</span><span class=p>(</span><span class=n>net</span><span class=o>.</span><span class=n>parameters</span><span class=p>()))</span><span class=o>.</span><span class=n>device</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>    <span class=c1># 正确预测的数量，总预测的数量</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>    <span class=n>metric</span> <span class=o>=</span> <span class=n>d2l</span><span class=o>.</span><span class=n>Accumulator</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>        <span class=k>for</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=ow>in</span> <span class=n>data_iter</span><span class=p>:</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=nb>list</span><span class=p>):</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>                <span class=c1># BERT微调所需的（之后将介绍）</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>                <span class=n>X</span> <span class=o>=</span> <span class=p>[</span><span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>X</span><span class=p>]</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a>            <span class=k>else</span><span class=p>:</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a>                <span class=n>X</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a>            <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>            <span class=n>metric</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>d2l</span><span class=o>.</span><span class=n>accuracy</span><span class=p>(</span><span class=n>net</span><span class=p>(</span><span class=n>X</span><span class=p>),</span> <span class=n>y</span><span class=p>),</span> <span class=n>y</span><span class=o>.</span><span class=n>numel</span><span class=p>())</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a>    <span class=k>return</span> <span class=n>metric</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>metric</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a><span class=c1>#@save</span>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a><span class=k>def</span><span class=w> </span><span class=nf>train_ch6</span><span class=p>(</span><span class=n>net</span><span class=p>,</span> <span class=n>train_iter</span><span class=p>,</span> <span class=n>test_iter</span><span class=p>,</span> <span class=n>num_epochs</span><span class=p>,</span> <span class=n>lr</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;用GPU训练模型(在第六章定义)&quot;&quot;&quot;</span>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>    <span class=k>def</span><span class=w> </span><span class=nf>init_weights</span><span class=p>(</span><span class=n>m</span><span class=p>):</span>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a>        <span class=k>if</span> <span class=nb>type</span><span class=p>(</span><span class=n>m</span><span class=p>)</span> <span class=o>==</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span> <span class=ow>or</span> <span class=nb>type</span><span class=p>(</span><span class=n>m</span><span class=p>)</span> <span class=o>==</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>:</span>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a>            <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_uniform_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span><span id=__span-8-26><a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a>    <span class=c1>#用xavier初始化权重</span>
</span><span id=__span-8-27><a id=__codelineno-8-27 name=__codelineno-8-27 href=#__codelineno-8-27></a>    <span class=n>net</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>init_weights</span><span class=p>)</span>
</span><span id=__span-8-28><a id=__codelineno-8-28 name=__codelineno-8-28 href=#__codelineno-8-28></a>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;training on&#39;</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span>
</span><span id=__span-8-29><a id=__codelineno-8-29 name=__codelineno-8-29 href=#__codelineno-8-29></a>    <span class=n>net</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-8-30><a id=__codelineno-8-30 name=__codelineno-8-30 href=#__codelineno-8-30></a>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>net</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>)</span>
</span><span id=__span-8-31><a id=__codelineno-8-31 name=__codelineno-8-31 href=#__codelineno-8-31></a>    <span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span><span id=__span-8-32><a id=__codelineno-8-32 name=__codelineno-8-32 href=#__codelineno-8-32></a>    <span class=c1>#设置动画效果(打印信息)</span>
</span><span id=__span-8-33><a id=__codelineno-8-33 name=__codelineno-8-33 href=#__codelineno-8-33></a>    <span class=n>animator</span> <span class=o>=</span> <span class=n>d2l</span><span class=o>.</span><span class=n>Animator</span><span class=p>(</span><span class=n>xlabel</span><span class=o>=</span><span class=s1>&#39;epoch&#39;</span><span class=p>,</span> <span class=n>xlim</span><span class=o>=</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_epochs</span><span class=p>],</span>
</span><span id=__span-8-34><a id=__codelineno-8-34 name=__codelineno-8-34 href=#__codelineno-8-34></a>                            <span class=n>legend</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;train loss&#39;</span><span class=p>,</span> <span class=s1>&#39;train acc&#39;</span><span class=p>,</span> <span class=s1>&#39;test acc&#39;</span><span class=p>])</span>
</span><span id=__span-8-35><a id=__codelineno-8-35 name=__codelineno-8-35 href=#__codelineno-8-35></a>    <span class=n>timer</span><span class=p>,</span> <span class=n>num_batches</span> <span class=o>=</span> <span class=n>d2l</span><span class=o>.</span><span class=n>Timer</span><span class=p>(),</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_iter</span><span class=p>)</span>
</span><span id=__span-8-36><a id=__codelineno-8-36 name=__codelineno-8-36 href=#__codelineno-8-36></a>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span><span id=__span-8-37><a id=__codelineno-8-37 name=__codelineno-8-37 href=#__codelineno-8-37></a>        <span class=c1># 训练损失之和，训练准确率之和，样本数</span>
</span><span id=__span-8-38><a id=__codelineno-8-38 name=__codelineno-8-38 href=#__codelineno-8-38></a>        <span class=n>metric</span> <span class=o>=</span> <span class=n>d2l</span><span class=o>.</span><span class=n>Accumulator</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
</span><span id=__span-8-39><a id=__codelineno-8-39 name=__codelineno-8-39 href=#__codelineno-8-39></a>        <span class=n>net</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-8-40><a id=__codelineno-8-40 name=__codelineno-8-40 href=#__codelineno-8-40></a>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_iter</span><span class=p>):</span>
</span><span id=__span-8-41><a id=__codelineno-8-41 name=__codelineno-8-41 href=#__codelineno-8-41></a>            <span class=n>timer</span><span class=o>.</span><span class=n>start</span><span class=p>()</span>
</span><span id=__span-8-42><a id=__codelineno-8-42 name=__codelineno-8-42 href=#__codelineno-8-42></a>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-8-43><a id=__codelineno-8-43 name=__codelineno-8-43 href=#__codelineno-8-43></a>            <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-8-44><a id=__codelineno-8-44 name=__codelineno-8-44 href=#__codelineno-8-44></a>            <span class=n>y_hat</span> <span class=o>=</span> <span class=n>net</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-8-45><a id=__codelineno-8-45 name=__codelineno-8-45 href=#__codelineno-8-45></a>            <span class=n>l</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>y_hat</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span><span id=__span-8-46><a id=__codelineno-8-46 name=__codelineno-8-46 href=#__codelineno-8-46></a>            <span class=n>l</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-8-47><a id=__codelineno-8-47 name=__codelineno-8-47 href=#__codelineno-8-47></a>            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-8-48><a id=__codelineno-8-48 name=__codelineno-8-48 href=#__codelineno-8-48></a>            <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-8-49><a id=__codelineno-8-49 name=__codelineno-8-49 href=#__codelineno-8-49></a>                <span class=n>metric</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>l</span> <span class=o>*</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>d2l</span><span class=o>.</span><span class=n>accuracy</span><span class=p>(</span><span class=n>y_hat</span><span class=p>,</span> <span class=n>y</span><span class=p>),</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span><span id=__span-8-50><a id=__codelineno-8-50 name=__codelineno-8-50 href=#__codelineno-8-50></a>            <span class=n>timer</span><span class=o>.</span><span class=n>stop</span><span class=p>()</span>
</span><span id=__span-8-51><a id=__codelineno-8-51 name=__codelineno-8-51 href=#__codelineno-8-51></a>            <span class=n>train_l</span> <span class=o>=</span> <span class=n>metric</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>metric</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span>
</span><span id=__span-8-52><a id=__codelineno-8-52 name=__codelineno-8-52 href=#__codelineno-8-52></a>            <span class=n>train_acc</span> <span class=o>=</span> <span class=n>metric</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>/</span> <span class=n>metric</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span>
</span><span id=__span-8-53><a id=__codelineno-8-53 name=__codelineno-8-53 href=#__codelineno-8-53></a>            <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=p>(</span><span class=n>num_batches</span> <span class=o>//</span> <span class=mi>5</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span> <span class=ow>or</span> <span class=n>i</span> <span class=o>==</span> <span class=n>num_batches</span> <span class=o>-</span> <span class=mi>1</span><span class=p>:</span>
</span><span id=__span-8-54><a id=__codelineno-8-54 name=__codelineno-8-54 href=#__codelineno-8-54></a>                <span class=n>animator</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>num_batches</span><span class=p>,</span>
</span><span id=__span-8-55><a id=__codelineno-8-55 name=__codelineno-8-55 href=#__codelineno-8-55></a>                             <span class=p>(</span><span class=n>train_l</span><span class=p>,</span> <span class=n>train_acc</span><span class=p>,</span> <span class=kc>None</span><span class=p>))</span>
</span><span id=__span-8-56><a id=__codelineno-8-56 name=__codelineno-8-56 href=#__codelineno-8-56></a>        <span class=c1>#打印信息</span>
</span><span id=__span-8-57><a id=__codelineno-8-57 name=__codelineno-8-57 href=#__codelineno-8-57></a>        <span class=n>test_acc</span> <span class=o>=</span> <span class=n>evaluate_accuracy_gpu</span><span class=p>(</span><span class=n>net</span><span class=p>,</span> <span class=n>test_iter</span><span class=p>)</span>
</span><span id=__span-8-58><a id=__codelineno-8-58 name=__codelineno-8-58 href=#__codelineno-8-58></a>        <span class=n>animator</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=n>test_acc</span><span class=p>))</span>
</span><span id=__span-8-59><a id=__codelineno-8-59 name=__codelineno-8-59 href=#__codelineno-8-59></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;loss </span><span class=si>{</span><span class=n>train_l</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>, train acc </span><span class=si>{</span><span class=n>train_acc</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>, &#39;</span>
</span><span id=__span-8-60><a id=__codelineno-8-60 name=__codelineno-8-60 href=#__codelineno-8-60></a>          <span class=sa>f</span><span class=s1>&#39;test acc </span><span class=si>{</span><span class=n>test_acc</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-8-61><a id=__codelineno-8-61 name=__codelineno-8-61 href=#__codelineno-8-61></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>metric</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>num_epochs</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=n>timer</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>:</span><span class=s1>.1f</span><span class=si>}</span><span class=s1> examples/sec &#39;</span>
</span><span id=__span-8-62><a id=__codelineno-8-62 name=__codelineno-8-62 href=#__codelineno-8-62></a>          <span class=sa>f</span><span class=s1>&#39;on </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>device</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></code></pre></div> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=页脚> <a href=../.. class="md-footer__link md-footer__link--prev" aria-label="上一页: Welcome to My Notebook"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> 上一页 </span> <div class=md-ellipsis> Welcome to My Notebook </div> </div> </a> <a href=../Modern%20CNN/ class="md-footer__link md-footer__link--next" aria-label="下一页: 现代卷积神经网络架构"> <div class=md-footer__title> <span class=md-footer__direction> 下一页 </span> <div class=md-ellipsis> 现代卷积神经网络架构 </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2023 ~ now | 🚀 Chen Wu (ShiSe) </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script> <script src=../../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../../js/baidu-tongji.js></script> <script src=../../js/katex.js></script> <script src=../../js/mathjax.js></script> <script src=https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script> </body> </html>