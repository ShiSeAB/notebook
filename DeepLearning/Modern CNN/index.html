<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Welcome to Shise's notebook. This site serves as a personal knowledge base for me to record my thoughts and ideas. It is also a place for me to share my knowledge and experience with the world. I hope you find something useful here. "><meta name=author content=ShiSeAB><link href=https://shiseab.github.io/notebook/DeepLearning/Modern%20CNN/ rel=canonical><link href=../Convolution/ rel=prev><link href=../Recurrent%20neural%20network/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.14"><title>现代卷积神经网络架构 - ShiSe的notebook</title><link rel=stylesheet href=../../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=LXGW+WenKai+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"LXGW WenKai Screen";--md-code-font:"JetBrains Mono"}</style><link rel=stylesheet href=../../css/timeline.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=../../css/custom.css><link rel=stylesheet href=../../css/card.css><link rel=stylesheet href=../../css/tasklist.css><link rel=stylesheet href=../../css/flink.css><link rel=stylesheet href=../../css/more_changelog.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=brown data-md-color-accent=brown> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../.. title=ShiSe的notebook class="md-header__button md-logo" aria-label=ShiSe的notebook data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> ShiSe的notebook </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 现代卷积神经网络架构 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=brown data-md-color-accent=brown aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=查找> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ShiSeAB/notebook.git/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> ShiSeAB/notebook </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> HOME </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../RL/basic_1/ class=md-tabs__link> AI </a> </li> <li class=md-tabs__item> <a href=../../Compiler/Lexical_Analysis/ class=md-tabs__link> CS课程 </a> </li> <li class=md-tabs__item> <a href=../../essays/DeepSeek-R1/ class=md-tabs__link> 论文阅读 </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=ShiSe的notebook class="md-nav__button md-logo" aria-label=ShiSe的notebook data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> ShiSe的notebook </label> <div class=md-nav__source> <a href=https://github.com/ShiSeAB/notebook.git/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> ShiSeAB/notebook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../.. class="md-nav__link "> <span class=md-ellipsis> HOME </span> </a> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> HOME </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> AI </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1> <label class=md-nav__link for=__nav_2_1 id=__nav_2_1_label tabindex=0> <span class=md-ellipsis> 强化学习 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> 强化学习 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../RL/basic_1/ class=md-nav__link> <span class=md-ellipsis> 基础知识 </span> </a> </li> <li class=md-nav__item> <a href=../../RL/TRPO/ class=md-nav__link> <span class=md-ellipsis> TRPO </span> </a> </li> <li class=md-nav__item> <a href=../../RL/PPO/ class=md-nav__link> <span class=md-ellipsis> PPO </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2 checked> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> 深度学习 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> 深度学习 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Convolution/ class=md-nav__link> <span class=md-ellipsis> 卷积神经网络 </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 现代卷积神经网络架构 </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 现代卷积神经网络架构 </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-alexnet class=md-nav__link> <span class=md-ellipsis> 1. AlexNet </span> </a> </li> <li class=md-nav__item> <a href=#2-vgg class=md-nav__link> <span class=md-ellipsis> 2. VGG </span> </a> <nav class=md-nav aria-label="2. VGG"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-vgg class=md-nav__link> <span class=md-ellipsis> 2.1 VGG块 </span> </a> </li> <li class=md-nav__item> <a href=#22-vgg class=md-nav__link> <span class=md-ellipsis> 2.2 VGG架构 </span> </a> </li> <li class=md-nav__item> <a href=#23 class=md-nav__link> <span class=md-ellipsis> 2.3 实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-nin class=md-nav__link> <span class=md-ellipsis> 3. NiN </span> </a> <nav class=md-nav aria-label="3. NiN"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-nin class=md-nav__link> <span class=md-ellipsis> 3.1 NiN块 </span> </a> </li> <li class=md-nav__item> <a href=#32-nin class=md-nav__link> <span class=md-ellipsis> 3.2 NiN架构 </span> </a> </li> <li class=md-nav__item> <a href=#33 class=md-nav__link> <span class=md-ellipsis> 3.3 实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-googlenet class=md-nav__link> <span class=md-ellipsis> 4. GoogLeNet </span> </a> <nav class=md-nav aria-label="4. GoogLeNet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-inception class=md-nav__link> <span class=md-ellipsis> 4.1 Inception块 </span> </a> </li> <li class=md-nav__item> <a href=#42-googlenet class=md-nav__link> <span class=md-ellipsis> 4.2 GoogLeNet </span> </a> </li> <li class=md-nav__item> <a href=#43-inception-v3 class=md-nav__link> <span class=md-ellipsis> 4.3 Inception V3 </span> </a> </li> <li class=md-nav__item> <a href=#44 class=md-nav__link> <span class=md-ellipsis> 4.4 实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5 class=md-nav__link> <span class=md-ellipsis> 5. 批量归一化 </span> </a> <nav class=md-nav aria-label="5. 批量归一化"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51 class=md-nav__link> <span class=md-ellipsis> 5.1 批量归一化层 </span> </a> </li> <li class=md-nav__item> <a href=#52 class=md-nav__link> <span class=md-ellipsis> 5.2 实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-resnet class=md-nav__link> <span class=md-ellipsis> 6. ResNet </span> </a> <nav class=md-nav aria-label="6. ResNet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#61 class=md-nav__link> <span class=md-ellipsis> 6.1 残差块 </span> </a> </li> <li class=md-nav__item> <a href=#62-resnet class=md-nav__link> <span class=md-ellipsis> 6.2 ResNet模型 </span> </a> </li> <li class=md-nav__item> <a href=#63 class=md-nav__link> <span class=md-ellipsis> 6.3 实现 </span> </a> </li> <li class=md-nav__item> <a href=#64-resnet class=md-nav__link> <span class=md-ellipsis> 6.4 ResNet 梯度计算 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Recurrent%20neural%20network/ class=md-nav__link> <span class=md-ellipsis> 循环神经网络 </span> </a> </li> <li class=md-nav__item> <a href=../Modern%20RNN/ class=md-nav__link> <span class=md-ellipsis> 现代循环神经网络 </span> </a> </li> <li class=md-nav__item> <a href="../Attention Mechanisms" class=md-nav__link> <span class=md-ellipsis> 注意力机制 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> CS课程 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> CS课程 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> 编译原理 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> 编译原理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Compiler/Lexical_Analysis/ class=md-nav__link> <span class=md-ellipsis> 词法分析 </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1_2> <label class=md-nav__link for=__nav_3_1_2 id=__nav_3_1_2_label tabindex=0> <span class=md-ellipsis> 语法分析 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1_2> <span class="md-nav__icon md-icon"></span> 语法分析 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Compiler/Parsing/ class=md-nav__link> <span class=md-ellipsis> Top-Down </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/Parsing-2/ class=md-nav__link> <span class=md-ellipsis> Bottom-Up </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../Compiler/Abstract_Syntax/ class=md-nav__link> <span class=md-ellipsis> 抽象语法 </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/Activation_Record/ class=md-nav__link> <span class=md-ellipsis> 活动记录 </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/Semantic_Analysis/ class=md-nav__link> <span class=md-ellipsis> 语义分析 </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/ch7-IR/ class=md-nav__link> <span class=md-ellipsis> 中间代码生成 </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/ch8/ class=md-nav__link> <span class=md-ellipsis> 基本块 </span> </a> </li> <li class=md-nav__item> <a href=../../Compiler/ch9/ class=md-nav__link> <span class=md-ellipsis> 指令选择 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> 自然语言处理导论 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 自然语言处理导论 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../nlp/Deep%20Learning%20Basic/ class=md-nav__link> <span class=md-ellipsis> 深度学习基础 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> 论文阅读 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> 论文阅读 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1> <label class=md-nav__link for=__nav_4_1 id=__nav_4_1_label tabindex=0> <span class=md-ellipsis> RL </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=false> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> RL </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../essays/DeepSeek-R1/ class=md-nav__link> <span class=md-ellipsis> DeepSeek-R1 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> CoT </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> CoT </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../essays/TokenSkip/ class=md-nav__link> <span class=md-ellipsis> TokenSkip </span> </a> </li> <li class=md-nav__item> <a href=../../essays/DEER/ class=md-nav__link> <span class=md-ellipsis> DEER </span> </a> </li> <li class=md-nav__item> <a href=../../essays/ThoughtTerminator/ class=md-nav__link> <span class=md-ellipsis> ThoughtTerminator </span> </a> </li> <li class=md-nav__item> <a href=../../essays/SEAL/ class=md-nav__link> <span class=md-ellipsis> SEAL </span> </a> </li> <li class=md-nav__item> <a href=../../essays/MRL/ class=md-nav__link> <span class=md-ellipsis> MRT </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex=0> <span class=md-ellipsis> Social </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> Social </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../essays/Social/SocialGenome/ class=md-nav__link> <span class=md-ellipsis> SocialGenome </span> </a> </li> <li class=md-nav__item> <a href=../../essays/Social/MiMeQA/ class=md-nav__link> <span class=md-ellipsis> MiMeQA </span> </a> </li> <li class=md-nav__item> <a href=../../essays/Social/EgoToM/ class=md-nav__link> <span class=md-ellipsis> EgoToM </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-alexnet class=md-nav__link> <span class=md-ellipsis> 1. AlexNet </span> </a> </li> <li class=md-nav__item> <a href=#2-vgg class=md-nav__link> <span class=md-ellipsis> 2. VGG </span> </a> <nav class=md-nav aria-label="2. VGG"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-vgg class=md-nav__link> <span class=md-ellipsis> 2.1 VGG块 </span> </a> </li> <li class=md-nav__item> <a href=#22-vgg class=md-nav__link> <span class=md-ellipsis> 2.2 VGG架构 </span> </a> </li> <li class=md-nav__item> <a href=#23 class=md-nav__link> <span class=md-ellipsis> 2.3 实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-nin class=md-nav__link> <span class=md-ellipsis> 3. NiN </span> </a> <nav class=md-nav aria-label="3. NiN"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-nin class=md-nav__link> <span class=md-ellipsis> 3.1 NiN块 </span> </a> </li> <li class=md-nav__item> <a href=#32-nin class=md-nav__link> <span class=md-ellipsis> 3.2 NiN架构 </span> </a> </li> <li class=md-nav__item> <a href=#33 class=md-nav__link> <span class=md-ellipsis> 3.3 实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-googlenet class=md-nav__link> <span class=md-ellipsis> 4. GoogLeNet </span> </a> <nav class=md-nav aria-label="4. GoogLeNet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-inception class=md-nav__link> <span class=md-ellipsis> 4.1 Inception块 </span> </a> </li> <li class=md-nav__item> <a href=#42-googlenet class=md-nav__link> <span class=md-ellipsis> 4.2 GoogLeNet </span> </a> </li> <li class=md-nav__item> <a href=#43-inception-v3 class=md-nav__link> <span class=md-ellipsis> 4.3 Inception V3 </span> </a> </li> <li class=md-nav__item> <a href=#44 class=md-nav__link> <span class=md-ellipsis> 4.4 实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5 class=md-nav__link> <span class=md-ellipsis> 5. 批量归一化 </span> </a> <nav class=md-nav aria-label="5. 批量归一化"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51 class=md-nav__link> <span class=md-ellipsis> 5.1 批量归一化层 </span> </a> </li> <li class=md-nav__item> <a href=#52 class=md-nav__link> <span class=md-ellipsis> 5.2 实现 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-resnet class=md-nav__link> <span class=md-ellipsis> 6. ResNet </span> </a> <nav class=md-nav aria-label="6. ResNet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#61 class=md-nav__link> <span class=md-ellipsis> 6.1 残差块 </span> </a> </li> <li class=md-nav__item> <a href=#62-resnet class=md-nav__link> <span class=md-ellipsis> 6.2 ResNet模型 </span> </a> </li> <li class=md-nav__item> <a href=#63 class=md-nav__link> <span class=md-ellipsis> 6.3 实现 </span> </a> </li> <li class=md-nav__item> <a href=#64-resnet class=md-nav__link> <span class=md-ellipsis> 6.4 ResNet 梯度计算 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=_1>现代神经网络架构<a class=headerlink href=#_1 title="Permanent link">&para;</a></h1> <p>​ 本章介绍的神经网络是将人类直觉和相关数学见解结合后，经过大量研究试错后的结晶。 将按照时间顺序介绍这些模型，在追寻历史的脉络的同时，帮助培养对该领域发展的直觉。这将有助于研究开发自己的架构。</p> <p>​ 例如，本章介绍的批量规范化（batch normalization）和残差网络（ResNet）为设计和训练深度神经网络提供了重要思想指导。</p> <h2 id=1-alexnet>1. AlexNet<a class=headerlink href=#1-alexnet title="Permanent link">&para;</a></h2> <p>本质上是一个更深更大的LeNet，做的改进有：</p> <ul> <li>丢弃法</li> <li>ReLu</li> <li>MaxPooling</li> </ul> <p>通过CNN学习图像特征（深度学习神经网络），再由softmax回归分类。</p> <p><img alt=image-20250308112643968 src=../Modern%20CNN.assets/image-20250308112643968.png></p> <p>​ 由于当时GPU运算性能不够，所以第一层卷积层步幅为4。输出通道数大大多于LeNet。更多细节：</p> <ul> <li>激活函数为ReLu</li> <li>隐藏全连接层后加入丢弃层</li> <li>数据增强</li> </ul> <p>复杂度：</p> <p><img alt=image-20250308113507595 src=../Modern%20CNN.assets/image-20250308113507595.png></p> <p>代码实现：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>from</span><span class=w> </span><span class=nn>torch</span><span class=w> </span><span class=kn>import</span> <span class=n>nn</span>
<a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>from</span><span class=w> </span><span class=nn>d2l</span><span class=w> </span><span class=kn>import</span> <span class=n>torch</span> <span class=k>as</span> <span class=n>d2l</span>
<a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>
<a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
<a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>    <span class=c1># 这里使用一个11*11的更大窗口来捕捉对象。</span>
<a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>    <span class=c1># 同时，步幅为4，以减少输出的高度和宽度。</span>
<a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>    <span class=c1># 另外，输出通道的数目远大于LeNet</span>
<a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>96</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>    <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
<a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>    <span class=c1># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span>
<a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>96</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>    <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
<a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>    <span class=c1># 使用三个连续的卷积层和较小的卷积窗口。</span>
<a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>    <span class=c1># 除了最后的卷积层，输出通道的数量进一步增加。</span>
<a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>    <span class=c1># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span>
<a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>384</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>384</span><span class=p>,</span> <span class=mi>384</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>384</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a>    <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
<a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span>
<a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a>    <span class=c1># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span>
<a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>6400</span><span class=p>,</span> <span class=mi>4096</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
<a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4096</span><span class=p>,</span> <span class=mi>4096</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
<a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a>    <span class=c1># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span>
<a id=__codelineno-0-28 name=__codelineno-0-28 href=#__codelineno-0-28></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4096</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</code></pre></div> <p>构造一个高宽都为224的单通道数据为输入，得到每层输出shape：</p> <p><img alt=image-20250308134133053 src=../Modern%20CNN.assets/image-20250308134133053.png></p> <h2 id=2-vgg>2. VGG<a class=headerlink href=#2-vgg title="Permanent link">&para;</a></h2> <h3 id=21-vgg>2.1 VGG块<a class=headerlink href=#21-vgg title="Permanent link">&para;</a></h3> <ul> <li>使用 <span class=arithmatex>\(3\times 3\)</span> 卷积，padding = 1，n个卷积层（n是超参数），m通道</li> <li>加上一个 <span class=arithmatex>\(2\times 2\)</span> 最大池化层，stride = 2</li> </ul> <p><img src=./Modern%20CNN.assets/image-20250308121311998.png alt=image-20250308121311998 style=zoom:53%;></p> <p>why <span class=arithmatex>\(3\times 3\)</span> : 研究发现深但窄效果会更好。</p> <h3 id=22-vgg>2.2 VGG架构<a class=headerlink href=#22-vgg title="Permanent link">&para;</a></h3> <p>多个VGG块连接后后接全连接层得到VGG架构，不同次数的重复块得到不同的架构。</p> <p><img alt=image-20250308122516320 src=../Modern%20CNN.assets/image-20250308122516320.png></p> <h3 id=23>2.3 实现<a class=headerlink href=#23 title="Permanent link">&para;</a></h3> <p>定义VGG块：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=kn>from</span><span class=w> </span><span class=nn>torch</span><span class=w> </span><span class=kn>import</span> <span class=n>nn</span>
<a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=kn>from</span><span class=w> </span><span class=nn>d2l</span><span class=w> </span><span class=kn>import</span> <span class=n>torch</span> <span class=k>as</span> <span class=n>d2l</span>
<a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>
<a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=c1>#卷积层的数量num_convs、输入通道的数量in_channels 和输出通道的数量out_channels.</span>
<a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=k>def</span><span class=w> </span><span class=nf>vgg_block</span><span class=p>(</span><span class=n>num_convs</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>):</span>
<a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>    <span class=n>layers</span> <span class=o>=</span> <span class=p>[]</span>
<a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_convs</span><span class=p>):</span>
<a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>        <span class=n>layers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span>
<a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>                                <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
<a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>        <span class=n>layers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>())</span>
<a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>        <span class=c1>#更新</span>
<a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>        <span class=n>in_channels</span> <span class=o>=</span> <span class=n>out_channels</span>
<a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>    <span class=n>layers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
<a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a>    <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=n>layers</span><span class=p>)</span>
</code></pre></div> <p>实现VGG-11：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=n>conv_arch</span> <span class=o>=</span> <span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>128</span><span class=p>),</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>256</span><span class=p>),</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>512</span><span class=p>),</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>512</span><span class=p>))</span>
<a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>
<a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=k>def</span><span class=w> </span><span class=nf>vgg</span><span class=p>(</span><span class=n>conv_arch</span><span class=p>):</span>
<a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>    <span class=n>conv_blks</span> <span class=o>=</span> <span class=p>[]</span>
<a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>    <span class=n>in_channels</span> <span class=o>=</span> <span class=mi>1</span>
<a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>    <span class=c1># 卷积层部分</span>
<a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>    <span class=k>for</span> <span class=p>(</span><span class=n>num_convs</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>)</span> <span class=ow>in</span> <span class=n>conv_arch</span><span class=p>:</span>
<a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>        <span class=n>conv_blks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>vgg_block</span><span class=p>(</span><span class=n>num_convs</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>))</span>
<a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>        <span class=n>in_channels</span> <span class=o>=</span> <span class=n>out_channels</span>
<a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a>
<a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>    <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
<a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>        <span class=o>*</span><span class=n>conv_blks</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span>
<a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a>        <span class=c1># 全连接层部分</span>
<a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>out_channels</span> <span class=o>*</span> <span class=mi>7</span> <span class=o>*</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>4096</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>),</span>
<a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4096</span><span class=p>,</span> <span class=mi>4096</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>),</span>
<a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4096</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
<a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a>
<a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a><span class=n>net</span> <span class=o>=</span> <span class=n>vgg</span><span class=p>(</span><span class=n>conv_arch</span><span class=p>)</span>
</code></pre></div> <p>同样是高宽都为244的单通道数据为输入，观察每层输出shape为：</p> <p><img alt=image-20250308134258927 src=../Modern%20CNN.assets/image-20250308134258927.png></p> <p>其训练速度比AlexNet慢，但精度高于AlexNet。</p> <h2 id=3-nin>3. NiN<a class=headerlink href=#3-nin title="Permanent link">&para;</a></h2> <p>全连接层的问题：</p> <ul> <li> <p>带来过拟合</p> </li> <li> <p>所需参数过多</p> </li> </ul> <p><img alt=image-20250308133858073 src=../Modern%20CNN.assets/image-20250308133858073.png></p> <h3 id=31-nin>3.1 NiN块<a class=headerlink href=#31-nin title="Permanent link">&para;</a></h3> <p>一个自定义的卷积层后跟两个 <span class=arithmatex>\(1\times 1\)</span> 卷积层，这两个 <span class=arithmatex>\(1\times 1\)</span> 卷积层步幅为1，无填充，输出形状和卷积层输出一样，起到全连接层的作用，对图片的每个像素增加了非线性性</p> <p><img alt=image-20250308134425262 src=../Modern%20CNN.assets/image-20250308134425262.png></p> <h3 id=32-nin>3.2 NiN架构<a class=headerlink href=#32-nin title="Permanent link">&para;</a></h3> <p><img alt=image-20250308134914570 src=../Modern%20CNN.assets/image-20250308134914570.png></p> <p>最后的一个层使用全局平均池化层替代VGG和AlexNet中的全连接层，更少的参数个数，不容易过拟合。</p> <h3 id=33>3.3 实现<a class=headerlink href=#33 title="Permanent link">&para;</a></h3> <p>nin块：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=kn>from</span><span class=w> </span><span class=nn>torch</span><span class=w> </span><span class=kn>import</span> <span class=n>nn</span>
<a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=kn>from</span><span class=w> </span><span class=nn>d2l</span><span class=w> </span><span class=kn>import</span> <span class=n>torch</span> <span class=k>as</span> <span class=n>d2l</span>
<a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>
<a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>
<a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=k>def</span><span class=w> </span><span class=nf>nin_block</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=p>,</span> <span class=n>strides</span><span class=p>,</span> <span class=n>padding</span><span class=p>):</span>
<a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>    <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
<a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>        <span class=c1>#自定义卷积层</span>
<a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=p>,</span> <span class=n>strides</span><span class=p>,</span> <span class=n>padding</span><span class=p>),</span>
<a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>        <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>        <span class=c1>#1x1卷积层+激活层，通道数不改变</span>
<a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>())</span>
</code></pre></div> <p>nin模型：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
<a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>    <span class=n>nin_block</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>96</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>0</span><span class=p>),</span>
<a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>    <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
<a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>    <span class=n>nin_block</span><span class=p>(</span><span class=mi>96</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
<a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>    <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
<a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=n>nin_block</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>384</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
<a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>    <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
<a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>),</span>
<a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=c1># 标签类别数是10，输出等于标签类别数</span>
<a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    <span class=n>nin_block</span><span class=p>(</span><span class=mi>384</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
<a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>    <span class=c1>#取10个通道中每个矩阵的平均，size变为[1,10,1,1]</span>
<a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>    <span class=n>nn</span><span class=o>.</span><span class=n>AdaptiveAvgPool2d</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)),</span>
<a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>    <span class=c1># 将四维的输出转成二维的输出，其形状为(批量大小,10)</span>
<a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Flatten</span><span class=p>())</span>
</code></pre></div> <p>同样创建一个224 x 224的数据样本来查看每个块的输出形状：</p> <p><img alt=image-20250308142315515 src=../Modern%20CNN.assets/image-20250308142315515.png></p> <h2 id=4-googlenet>4. GoogLeNet<a class=headerlink href=#4-googlenet title="Permanent link">&para;</a></h2> <p>GoogLeNet吸收了NiN中串联网络的思想，并在此基础上做了改进。提出该网络的论文解决了什么样大小的卷积核最合适的问题。</p> <h3 id=41-inception>4.1 Inception块<a class=headerlink href=#41-inception title="Permanent link">&para;</a></h3> <p>在GoogLeNet中，基本的卷积块被称为<em>Inception块</em> ：</p> <p><img alt=image-20250308151440727 src=../Modern%20CNN.assets/image-20250308151440727.png></p> <ul> <li> <p>Inception块由四条并行路径组成，都使用合适的填充来使输入与输出的高和宽一致。</p> </li> <li> <p>四个路径从不同层面抽取信息，最后我们将每条线路的输出在通道维度上连结，并构成Inception块的输出。（白色层用于变换通道数，蓝色层用于提取信息）</p> </li> <li> <p>在Inception块中，通常调整的超参数是<strong>每条线路的输出通道数</strong>。</p> </li> <li> <p>与单3 x 3或5 x 5卷积层比，Inception块有更少的参数个数和计算复杂度</p> </li> </ul> <p><img alt=image-20250308152840697 src=../Modern%20CNN.assets/image-20250308152840697.png></p> <p>Inception之后有各种变种，这里介绍的是初始版本。</p> <h3 id=42-googlenet>4.2 GoogLeNet<a class=headerlink href=#42-googlenet title="Permanent link">&para;</a></h3> <ul> <li>GoogLeNet一共使用9个Inception块和全局平均汇聚层的堆叠来生成其估计值，是第一个达到上百层的网络。</li> <li>Inception块之间的最大汇聚层可降低维度</li> </ul> <p><img alt=image-20250308153329491 src=../Modern%20CNN.assets/image-20250308153329491.png></p> <p>段1 &amp; 2：</p> <p><img alt=image-20250308153534168 src=../Modern%20CNN.assets/image-20250308153534168.png></p> <p>GoogLeNet 降宽更为缓和。</p> <p>段3：</p> <p><img alt=image-20250308153735659 src=../Modern%20CNN.assets/image-20250308153735659.png></p> <p>段4&amp;5：</p> <p><img alt=image-20250308154520742 src=../Modern%20CNN.assets/image-20250308154520742.png></p> <h3 id=43-inception-v3>4.3 Inception V3<a class=headerlink href=#43-inception-v3 title="Permanent link">&para;</a></h3> <p><img alt=image-20250308154712939 src=../Modern%20CNN.assets/image-20250308154712939.png></p> <p><img alt=image-20250308154837938 src=../Modern%20CNN.assets/image-20250308154837938.png></p> <p><img alt=image-20250308154852317 src=../Modern%20CNN.assets/image-20250308154852317.png></p> <p><img alt=image-20250308154820742 src=../Modern%20CNN.assets/image-20250308154820742.png></p> <h3 id=44>4.4 实现<a class=headerlink href=#44 title="Permanent link">&para;</a></h3> <p>实现见网站，没有什么好讲的，就根据模型来。</p> <h2 id=5>5. 批量归一化<a class=headerlink href=#5 title="Permanent link">&para;</a></h2> <p>数据从最底层往上传递（正向），而梯度从最顶层往下算（反向传输），权重从顶至下更新，梯度往下传输时越来越小，所以下面收敛更慢。而当底部层变化，所有层都要跟着变化，导致收敛变慢</p> <p>为避免在学习底部层时避免顶部层变化，我们运用 <strong>批量归一化</strong> 来解决这个问题。</p> <p>将输入的小批量样本里的均值和方差求出来（在方差估计值中添加一个小的常量 <span class=arithmatex>\(\epsilon &gt; 0\)</span>，以确保我们永远不会尝试除以零）：</p> <p><img alt=image-20250308163949203 src=../Modern%20CNN.assets/image-20250308163949203.png></p> <p>应用标准化，使得生成的小批量输出的平均值为0和单位方差为1：</p> <p><img alt=image-20250308164032107 src=../Modern%20CNN.assets/image-20250308164032107.png></p> <p><span class=arithmatex>\(\gamma,\beta\)</span>是需要和其它模型参数一起学习的参数，分别叫做拉伸参数scale和偏移参数shift。</p> <p>这<strong>加快了收敛速度</strong>，但一般不改变模型精度。</p> <h3 id=51>5.1 批量归一化层<a class=headerlink href=#51 title="Permanent link">&para;</a></h3> <p>批量归一化是起一个线性作用。</p> <ul> <li>该层中可学习的参数为 <span class=arithmatex>\(\gamma\)</span> 和 <span class=arithmatex>\(\beta\)</span></li> <li>它直接作用在全连接层和卷积层输出上，激活函数连在它后面</li> <li>作用在全连接层和卷积层输入上</li> <li>对于全连接层，作用在特征维；把每一个特征对应的列设均值和方差</li> <li>对于卷积层，作用在通道维；假设一个像素通道为100维，那么这100维的向量就是这个像素的特征，每个像素看作一个样本。</li> </ul> <p>批量归一化是在做什么？</p> <ul> <li>通过在每个小批量里加入噪音来控制模型复杂度，<span class=arithmatex>\(\sigma_B\)</span> 和 <span class=arithmatex>\(\mu_B\)</span> 是随机选取的小批量样本的方差和均值，可看作噪音：</li> </ul> <p><img alt=image-20250308165256757 src=../Modern%20CNN.assets/image-20250308165256757.png></p> <h3 id=52>5.2 实现<a class=headerlink href=#52 title="Permanent link">&para;</a></h3> <p>数据计算：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=kn>from</span><span class=w> </span><span class=nn>torch</span><span class=w> </span><span class=kn>import</span> <span class=n>nn</span>
<a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=kn>from</span><span class=w> </span><span class=nn>d2l</span><span class=w> </span><span class=kn>import</span> <span class=n>torch</span> <span class=k>as</span> <span class=n>d2l</span>
<a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>
<a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=k>def</span><span class=w> </span><span class=nf>batch_norm</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>gamma</span><span class=p>,</span> <span class=n>beta</span><span class=p>,</span> <span class=n>moving_mean</span><span class=p>,</span> <span class=n>moving_var</span><span class=p>,</span> <span class=n>eps</span><span class=p>,</span> <span class=n>momentum</span><span class=p>):</span>
<a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>    <span class=c1># 通过is_grad_enabled来判断当前模式是训练模式还是预测模式</span>
<a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>torch</span><span class=o>.</span><span class=n>is_grad_enabled</span><span class=p>():</span>
<a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>        <span class=c1># 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差</span>
<a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>        <span class=n>X_hat</span> <span class=o>=</span> <span class=p>(</span><span class=n>X</span> <span class=o>-</span> <span class=n>moving_mean</span><span class=p>)</span> <span class=o>/</span> <span class=n>torch</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>moving_var</span> <span class=o>+</span> <span class=n>eps</span><span class=p>)</span>
<a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>    <span class=k>else</span><span class=p>:</span>
<a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>        <span class=c1>#2维是全连接层 4维是卷积层</span>
<a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>        <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=ow>in</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>
<a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>            <span class=c1># 使用全连接层的情况，计算特征维上的均值和方差</span>
<a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a>            <span class=n>mean</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a>            <span class=n>var</span> <span class=o>=</span> <span class=p>((</span><span class=n>X</span> <span class=o>-</span> <span class=n>mean</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>        <span class=k>else</span><span class=p>:</span>
<a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a>            <span class=c1># 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。</span>
<a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a>            <span class=c1># 这里我们需要保持X的形状以便后面可以做广播运算</span>
<a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a>            <span class=n>mean</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<a id=__codelineno-5-21 name=__codelineno-5-21 href=#__codelineno-5-21></a>            <span class=n>var</span> <span class=o>=</span> <span class=p>((</span><span class=n>X</span> <span class=o>-</span> <span class=n>mean</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<a id=__codelineno-5-22 name=__codelineno-5-22 href=#__codelineno-5-22></a>        <span class=c1># 训练模式下，用当前的均值和方差做标准化</span>
<a id=__codelineno-5-23 name=__codelineno-5-23 href=#__codelineno-5-23></a>        <span class=n>X_hat</span> <span class=o>=</span> <span class=p>(</span><span class=n>X</span> <span class=o>-</span> <span class=n>mean</span><span class=p>)</span> <span class=o>/</span> <span class=n>torch</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>var</span> <span class=o>+</span> <span class=n>eps</span><span class=p>)</span>
<a id=__codelineno-5-24 name=__codelineno-5-24 href=#__codelineno-5-24></a>        <span class=c1># 更新移动平均的均值和方差 momentum一般为0.9</span>
<a id=__codelineno-5-25 name=__codelineno-5-25 href=#__codelineno-5-25></a>        <span class=n>moving_mean</span> <span class=o>=</span> <span class=n>momentum</span> <span class=o>*</span> <span class=n>moving_mean</span> <span class=o>+</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=n>momentum</span><span class=p>)</span> <span class=o>*</span> <span class=n>mean</span>
<a id=__codelineno-5-26 name=__codelineno-5-26 href=#__codelineno-5-26></a>        <span class=n>moving_var</span> <span class=o>=</span> <span class=n>momentum</span> <span class=o>*</span> <span class=n>moving_var</span> <span class=o>+</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=n>momentum</span><span class=p>)</span> <span class=o>*</span> <span class=n>var</span>
<a id=__codelineno-5-27 name=__codelineno-5-27 href=#__codelineno-5-27></a>    <span class=n>Y</span> <span class=o>=</span> <span class=n>gamma</span> <span class=o>*</span> <span class=n>X_hat</span> <span class=o>+</span> <span class=n>beta</span>  <span class=c1># 缩放和移位</span>
<a id=__codelineno-5-28 name=__codelineno-5-28 href=#__codelineno-5-28></a>    <span class=k>return</span> <span class=n>Y</span><span class=p>,</span> <span class=n>moving_mean</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=n>moving_var</span><span class=o>.</span><span class=n>data</span>
</code></pre></div> <p>创建一个正确的 <code>BatchNorm</code> 图层：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=k>class</span><span class=w> </span><span class=nc>BatchNorm</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
<a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>    <span class=c1># num_features：完全连接层的输出数量或卷积层的输出通道数。</span>
<a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>    <span class=c1># num_dims：2表示完全连接层，4表示卷积层</span>
<a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_features</span><span class=p>,</span> <span class=n>num_dims</span><span class=p>):</span>
<a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
<a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>        <span class=k>if</span> <span class=n>num_dims</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>
<a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>            <span class=n>shape</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_features</span><span class=p>)</span>
<a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>        <span class=k>else</span><span class=p>:</span>
<a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>            <span class=n>shape</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_features</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>        <span class=c1># 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0</span>
<a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>        <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>shape</span><span class=p>))</span>
<a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>        <span class=bp>self</span><span class=o>.</span><span class=n>beta</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>shape</span><span class=p>))</span>
<a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>        <span class=c1># 非模型参数的变量初始化为0和1</span>
<a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>        <span class=bp>self</span><span class=o>.</span><span class=n>moving_mean</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>shape</span><span class=p>)</span>
<a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>        <span class=bp>self</span><span class=o>.</span><span class=n>moving_var</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>shape</span><span class=p>)</span>
<a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>
<a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
<a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a>        <span class=c1># 如果X不在内存上，将moving_mean和moving_var</span>
<a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a>        <span class=c1># 复制到X所在显存上</span>
<a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>moving_mean</span><span class=o>.</span><span class=n>device</span> <span class=o>!=</span> <span class=n>X</span><span class=o>.</span><span class=n>device</span><span class=p>:</span>
<a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a>            <span class=bp>self</span><span class=o>.</span><span class=n>moving_mean</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>moving_mean</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
<a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>            <span class=bp>self</span><span class=o>.</span><span class=n>moving_var</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>moving_var</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
<a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a>        <span class=c1># 保存更新过的moving_mean和moving_var</span>
<a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a>        <span class=n>Y</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>moving_mean</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>moving_var</span> <span class=o>=</span> <span class=n>batch_norm</span><span class=p>(</span>
<a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a>            <span class=n>X</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>beta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>moving_mean</span><span class=p>,</span>
<a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a>            <span class=bp>self</span><span class=o>.</span><span class=n>moving_var</span><span class=p>,</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-5</span><span class=p>,</span> <span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
<a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a>        <span class=k>return</span> <span class=n>Y</span>
</code></pre></div> <p>除了使用我们刚刚定义的<code>BatchNorm</code>，我们也可以直接使用深度学习框架中定义的<code>BatchNorm</code>：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
<a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>6</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>(),</span>
<a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>    <span class=n>nn</span><span class=o>.</span><span class=n>AvgPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
<a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>16</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>(),</span>
<a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>    <span class=n>nn</span><span class=o>.</span><span class=n>AvgPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span>
<a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>120</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>120</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>(),</span>
<a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>120</span><span class=p>,</span> <span class=mi>84</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>84</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>(),</span>
<a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>84</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</code></pre></div> <p>通常高级API变体运行速度快得多，因为它的代码已编译为C++或CUDA，而我们的自定义代码由Python实现。</p> <h2 id=6-resnet>6. ResNet<a class=headerlink href=#6-resnet title="Permanent link">&para;</a></h2> <p>​ 假设 <span class=arithmatex>\(f^*\)</span> 是最佳训练函数，<span class=arithmatex>\(F\)</span> 是一类特定的神经网络架构。如果 <span class=arithmatex>\(f^* \in F\)</span>，那么可以通过训练神经网络得到最佳选择。但大多数时候 <span class=arithmatex>\(f^*\)</span> 不在架构中，这时我们通过构造一个更强大的 <span class=arithmatex>\(F\)</span> 架构，使其更接近最优解 <span class=arithmatex>\(f^*\)</span>。</p> <ul> <li>在面对非嵌套函数 non-nested function 时，架构更复杂反而可能远离最优解。例如 <span class=arithmatex>\(F_6\)</span> 较 <span class=arithmatex>\(F_3\)</span> 更加复杂，却离最优解更远。</li> <li>nested-function则没有这种烦恼，因为每一个更复杂的模型都包含了前面的模型。</li> </ul> <p><img alt=image-20250310113116198 src=../Modern%20CNN.assets/image-20250310113116198.png></p> <h3 id=61>6.1 残差块<a class=headerlink href=#61 title="Permanent link">&para;</a></h3> <p>​ 由此，我们需要构造 nested-function。</p> <p><img alt=image-20250310131045425 src=../Modern%20CNN.assets/image-20250310131045425-1741583446166-1.png></p> <p>​ 当 <span class=arithmatex>\(f(x)\)</span> 无效时，输出就是输入 x（也就是更小架构的输出）。这使得很深的网络更加容易训练。</p> <p>​ 在ResNet中，残差块结构为：</p> <p><img alt=image-20250310212517479 src=../Modern%20CNN.assets/image-20250310212517479.png></p> <p>​ 当<code>use_1x1conv=False</code>时，应用ReLU非线性函数之前，将输入添加到输出。 另一种是当<code>use_1x1conv=True</code>时，添加通过1×1卷积调整通道和分辨率。</p> <p>代码：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=kn>from</span><span class=w> </span><span class=nn>torch</span><span class=w> </span><span class=kn>import</span> <span class=n>nn</span>
<a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=kn>import</span> <span class=n>functional</span> <span class=k>as</span> <span class=n>F</span>
<a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=kn>from</span><span class=w> </span><span class=nn>d2l</span><span class=w> </span><span class=kn>import</span> <span class=n>torch</span> <span class=k>as</span> <span class=n>d2l</span>
<a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>
<a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>
<a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=k>class</span><span class=w> </span><span class=nc>Residual</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>  <span class=c1>#@save</span>
<a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_channels</span><span class=p>,</span> <span class=n>num_channels</span><span class=p>,</span>
<a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>                 <span class=n>use_1x1conv</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
<a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
<a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>        <span class=c1>#定义第一个3 x 3卷积层</span>
<a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>input_channels</span><span class=p>,</span> <span class=n>num_channels</span><span class=p>,</span>
<a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>                               <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>strides</span><span class=p>)</span>
<a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a>        <span class=c1>#第二个</span>
<a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a>        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>num_channels</span><span class=p>,</span> <span class=n>num_channels</span><span class=p>,</span>
<a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a>                               <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>        <span class=k>if</span> <span class=n>use_1x1conv</span><span class=p>:</span>
<a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a>            <span class=bp>self</span><span class=o>.</span><span class=n>conv3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>input_channels</span><span class=p>,</span> <span class=n>num_channels</span><span class=p>,</span>
<a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>                                   <span class=n>kernel_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>strides</span><span class=p>)</span>
<a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>        <span class=k>else</span><span class=p>:</span>
<a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a>            <span class=bp>self</span><span class=o>.</span><span class=n>conv3</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a>        <span class=c1>#batch_norm层</span>
<a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>        <span class=bp>self</span><span class=o>.</span><span class=n>bn1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>num_channels</span><span class=p>)</span>
<a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a>        <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>num_channels</span><span class=p>)</span>
<a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a>
<a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
<a id=__codelineno-8-27 name=__codelineno-8-27 href=#__codelineno-8-27></a>        <span class=n>Y</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>X</span><span class=p>)))</span>
<a id=__codelineno-8-28 name=__codelineno-8-28 href=#__codelineno-8-28></a>        <span class=n>Y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>Y</span><span class=p>))</span>
<a id=__codelineno-8-29 name=__codelineno-8-29 href=#__codelineno-8-29></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv3</span><span class=p>:</span>
<a id=__codelineno-8-30 name=__codelineno-8-30 href=#__codelineno-8-30></a>            <span class=n>X</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv3</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
<a id=__codelineno-8-31 name=__codelineno-8-31 href=#__codelineno-8-31></a>        <span class=n>Y</span> <span class=o>+=</span> <span class=n>X</span>  <span class=c1>#f(x) + x</span>
<a id=__codelineno-8-32 name=__codelineno-8-32 href=#__codelineno-8-32></a>        <span class=k>return</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>Y</span><span class=p>)</span>
</code></pre></div> <h3 id=62-resnet>6.2 ResNet模型<a class=headerlink href=#62-resnet title="Permanent link">&para;</a></h3> <p>​ ResNet的前两层跟之前介绍的GoogLeNet中的一样： 在输出通道数为64、步幅为2的7×7卷积层后，接步幅为2的3×3的最大汇聚层。 不同之处在于ResNet每个卷积层后增加了<strong>批量规范化层</strong>。</p> <p>​ GoogLeNet在后面接了4个由Inception块组成的模块。 ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。 </p> <h3 id=63>6.3 实现<a class=headerlink href=#63 title="Permanent link">&para;</a></h3> <div class=highlight><pre><span></span><code><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1>#初始块</span>
<a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=n>b1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>7</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>3</span><span class=p>),</span>
<a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>                   <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
<a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>                   <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
<a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>
<a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=k>def</span><span class=w> </span><span class=nf>resnet_block</span><span class=p>(</span><span class=n>input_channels</span><span class=p>,</span> <span class=n>num_channels</span><span class=p>,</span> <span class=n>num_residuals</span><span class=p>,</span>
<a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>                 <span class=n>first_block</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
<a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>    <span class=n>blk</span> <span class=o>=</span> <span class=p>[]</span>
<a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_residuals</span><span class=p>):</span>
<a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>        <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=mi>0</span> <span class=ow>and</span> <span class=ow>not</span> <span class=n>first_block</span><span class=p>:</span>
<a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>            <span class=c1>#每部分残差块的第一块stride=2 高宽减半；第一部分残差块除外</span>
<a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a>            <span class=n>blk</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>Residual</span><span class=p>(</span><span class=n>input_channels</span><span class=p>,</span> <span class=n>num_channels</span><span class=p>,</span>
<a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a>                                <span class=n>use_1x1conv</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
<a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a>        <span class=k>else</span><span class=p>:</span>
<a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a>            <span class=n>blk</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>Residual</span><span class=p>(</span><span class=n>num_channels</span><span class=p>,</span> <span class=n>num_channels</span><span class=p>))</span>
<a id=__codelineno-9-16 name=__codelineno-9-16 href=#__codelineno-9-16></a>    <span class=k>return</span> <span class=n>blk</span>
<a id=__codelineno-9-17 name=__codelineno-9-17 href=#__codelineno-9-17></a>
<a id=__codelineno-9-18 name=__codelineno-9-18 href=#__codelineno-9-18></a><span class=c1>#接入残差块，每部分num_residuals = 2</span>
<a id=__codelineno-9-19 name=__codelineno-9-19 href=#__codelineno-9-19></a><span class=n>b2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=n>resnet_block</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>first_block</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
<a id=__codelineno-9-20 name=__codelineno-9-20 href=#__codelineno-9-20></a><span class=n>b3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=n>resnet_block</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>
<a id=__codelineno-9-21 name=__codelineno-9-21 href=#__codelineno-9-21></a><span class=n>b4</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=n>resnet_block</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>
<a id=__codelineno-9-22 name=__codelineno-9-22 href=#__codelineno-9-22></a><span class=n>b5</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=n>resnet_block</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>
<a id=__codelineno-9-23 name=__codelineno-9-23 href=#__codelineno-9-23></a>
<a id=__codelineno-9-24 name=__codelineno-9-24 href=#__codelineno-9-24></a><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=n>b1</span><span class=p>,</span> <span class=n>b2</span><span class=p>,</span> <span class=n>b3</span><span class=p>,</span> <span class=n>b4</span><span class=p>,</span> <span class=n>b5</span><span class=p>,</span>
<a id=__codelineno-9-25 name=__codelineno-9-25 href=#__codelineno-9-25></a>                    <span class=n>nn</span><span class=o>.</span><span class=n>AdaptiveAvgPool2d</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>)),</span>
<a id=__codelineno-9-26 name=__codelineno-9-26 href=#__codelineno-9-26></a>                    <span class=n>nn</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</code></pre></div> <h3 id=64-resnet>6.4 ResNet 梯度计算<a class=headerlink href=#64-resnet title="Permanent link">&para;</a></h3> <p>​ 为什么 ResNet 可以设计得很深却不会发生梯度消失，原因如下： $$ y = f(x)\ w = w - \eta \frac{\partial y}{\partial w}\ 假设y是底层的一个输出，我们需要使得\frac{\partial y}{\partial w}不会很小\ y\prime = g(f(x))是y经过残差块之后的输出\ \frac{\partial y\prime}{\partial w} = \frac{\partial y\prime}{\partial y} \frac{\partial y}{\partial w} = \frac{\partial g(y)}{\partial y}\frac{\partial y}{\partial w} \ 假如\frac{\partial g(y)}{\partial y}很小，就会使得\frac{\partial y\prime}{\partial w}变小\ y\prime \prime = f(x) + g(f(x)) = y + y\prime\ \frac{\partial y\prime \prime}{\partial w} = \frac{\partial y}{\partial w} + \frac{\partial y\prime}{\partial w}\ 即使 \frac{\partial y\prime}{\partial w}小也没事，\frac{\partial y}{\partial w}会把结果拉回来 $$ 注：此处 <span class=arithmatex>\(y\prime\)</span> ，<span class=arithmatex>\(y\prime \prime\)</span> 和 <span class=arithmatex>\(y\)</span> 之间没有求导关系，表示从下往上残差块之间的输出。因为ResNet有跳转，所以直接可以获取底层的梯度并保证其不会太小。</p> <!-- Giscus --> <h2 id=__comments>评论</h2> <!-- 这里改成你的Giscus代码 --> <script src=https://giscus.app/client.js data-repo=HobbitQia/notebook data-repo-id=R_kgDOHtZjDg data-category=General data-category-id=DIC_kwDOHtZjDs4CQZ7Z data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=zh-CN crossorigin=anonymous async>
</script> <!-- Reload on palette change --> <script>
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object")
        if (palette.color.scheme === "slate") {
            var giscus = document.querySelector("script[src*=giscus]")
            giscus.setAttribute("data-theme", "dark")
        }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate" ? "dark" : "light"

                /* Instruct Giscus to change theme */
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    { giscus: { setConfig: { theme } } },
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2023 ~ now | 🚀 Chen Wu (ShiSe) </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script> <script src=../../assets/javascripts/bundle.13a4f30d.min.js></script> <script src=../../js/baidu-tongji.js></script> <script src=../../js/katex.js></script> <script src=../../js/mathjax.js></script> <script src=https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script> </body> </html>